+ [[ env_sem == \e\n\v ]]
+ [[ env_sem == \e\n\v\_\s\e\m ]]
+ echo 'In ObjectNav Env DDP SemSeg'
+ srun /private/home/abhshkdz/.conda/envs/habitat-on-web/bin/python -u -m habitat_baselines.run --exp-config habitat_baselines/config/objectnav/il_ddp_env_objectnav_semseg.yaml --run-type train
2022-01-26 10:31:30,957 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:30,957 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:30,957 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:30,957 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:30,957 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:30,957 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:30,957 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:30,957 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,082 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,082 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,082 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,082 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,082 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,082 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,082 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,082 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,121 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,121 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,121 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,121 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,121 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,121 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,121 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,121 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,123 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    use_normalized_advantage: True
    value_loss_coef: 0.5
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,123 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,123 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,123 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,123 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,123 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,123 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,123 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,300 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,300 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,300 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,300 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,300 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,300 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,300 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,300 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,349 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,349 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,349 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,349 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,349 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,349 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,349 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,349 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,424 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,424 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,424 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,424 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,424 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,424 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,424 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,424 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:31,718 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,718 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,718 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,718 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,718 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,718 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:31:31,718 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:31:31,718 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:31:34,028 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,064 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,073 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,089 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,105 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,105 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,120 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,126 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,127 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,135 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,137 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,147 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,148 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,154 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,160 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,167 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,169 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,170 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,173 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,176 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,178 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,180 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,181 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,182 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,183 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,182 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,183 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,186 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,187 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,187 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,188 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,188 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,189 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,189 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,190 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,192 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,193 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,195 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,197 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,199 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,199 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,200 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,201 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,200 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,204 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,205 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,205 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,206 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,207 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,207 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,207 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,208 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,208 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,213 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,214 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,216 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,217 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,218 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,218 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,219 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,222 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,223 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,235 Initializing dataset ObjectNav-v2
2022-01-26 10:31:34,237 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,090 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,090 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,091 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,091 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,091 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,092 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,094 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,094 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,095 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,162 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,162 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,162 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,162 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,164 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,167 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,167 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,167 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,168 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,169 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,169 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,169 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,169 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,171 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,170 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,173 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,173 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,173 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,174 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,174 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,176 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,176 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,176 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,177 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,180 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,180 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,180 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,202 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,225 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,225 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,226 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,226 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,226 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,226 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,227 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,228 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,232 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,233 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,304 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,314 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,314 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,314 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,314 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,314 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,315 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,320 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,320 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,320 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,324 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,325 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,325 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,325 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,325 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,325 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,327 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,328 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,329 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,344 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,350 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,351 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,365 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,368 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,367 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,372 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,374 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,375 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,376 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,376 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,376 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,376 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,377 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,377 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,378 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,381 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,382 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,386 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,386 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,386 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,390 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,391 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,400 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,401 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,401 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,408 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,409 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,414 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,413 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,420 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,422 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,425 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,430 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,430 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,430 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,430 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,430 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,433 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,434 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,435 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,436 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,437 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,438 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,437 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,441 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,441 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,441 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,441 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,445 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,445 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,446 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,447 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,447 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,448 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,448 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,450 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,454 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,456 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,460 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,459 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,460 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,461 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,464 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,465 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,466 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,466 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,466 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,467 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,468 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,470 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,471 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,472 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,474 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,475 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,476 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,479 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,479 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,482 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,482 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,482 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,483 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,484 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,483 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,483 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,486 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,486 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,486 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,490 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,491 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,491 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,495 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,497 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,498 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,498 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,500 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,501 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,501 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,505 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,510 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,512 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,512 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,512 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,513 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,514 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,515 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,515 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,515 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,516 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,516 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,518 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,518 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,520 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,521 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,524 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,525 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,527 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,528 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,527 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,527 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,528 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,530 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,530 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,531 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,532 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,532 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,534 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,534 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,535 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,536 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,537 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,538 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,538 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,540 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,541 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,543 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,544 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,544 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,544 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,544 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,546 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,546 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,546 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,547 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,548 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,548 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,550 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,550 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,550 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,551 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,551 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,552 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,553 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,554 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,555 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,555 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,556 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,557 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,557 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,558 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,558 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,558 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,559 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,559 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,561 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,562 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,563 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,563 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,564 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,563 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,564 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,565 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,565 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,566 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,566 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,566 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,568 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,568 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,568 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,570 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,570 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,570 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,571 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,571 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,575 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,584 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,584 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,585 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,585 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,586 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,586 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,586 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,586 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,588 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,589 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,589 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,590 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,590 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,590 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,590 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,590 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,590 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,590 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,591 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,591 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,591 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,594 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,594 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,594 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,596 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,595 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,597 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,599 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,599 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,599 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,602 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,603 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,603 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,604 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,604 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,605 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,605 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,605 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,605 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,606 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,606 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,605 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,605 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,607 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,607 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,608 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,609 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,609 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,610 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,610 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,610 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,610 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,611 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,611 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,613 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,614 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,614 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,614 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,614 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,614 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,615 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,615 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,615 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,616 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,620 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,620 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,620 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,620 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,617 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,623 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,624 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,624 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,624 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,624 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,624 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,627 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,627 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,627 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,629 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,630 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,629 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,630 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,631 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,632 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,634 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,635 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,636 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,637 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,637 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,640 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,640 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,641 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,643 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,643 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,644 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,645 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,645 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,645 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,645 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,647 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,647 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,648 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,648 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,651 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,653 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,653 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,657 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,657 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,658 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,660 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,660 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,660 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,661 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,663 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,664 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,665 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,666 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,666 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,668 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,669 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,669 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,669 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,670 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,671 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,672 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,675 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,675 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,675 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,675 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,676 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,678 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,678 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,678 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,677 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,679 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,679 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,679 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,681 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,685 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,687 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,688 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,693 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,694 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,695 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,696 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,696 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,696 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,697 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,699 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,699 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,702 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,702 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,704 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,705 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,705 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,706 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,710 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,711 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,712 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,715 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,718 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,718 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,718 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,723 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,724 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,726 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,726 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,729 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,731 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,731 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,732 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,732 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,734 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,735 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,736 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,736 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,737 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,739 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,744 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,744 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,745 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,746 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,747 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,749 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,749 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,750 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,753 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,761 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,761 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,761 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,763 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,764 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,765 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,769 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,770 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,770 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,777 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,780 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,784 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,787 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,795 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,796 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,800 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,807 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,808 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,811 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,816 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,819 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,823 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,830 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,832 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,836 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,838 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,842 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,843 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,847 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,851 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,851 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,856 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,858 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,860 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,860 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,864 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,869 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,880 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,883 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,884 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,891 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,895 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,900 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,923 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,927 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,933 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,933 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,933 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,937 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,959 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,961 Initializing dataset ObjectNav-v2
2022-01-26 10:31:41,963 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,013 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,055 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,059 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,082 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,095 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,120 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,144 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,162 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,188 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,249 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,306 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,389 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,409 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,539 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,542 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,605 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,661 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,848 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,948 Initializing dataset ObjectNav-v2
2022-01-26 10:31:42,985 Initializing dataset ObjectNav-v2
2022-01-26 10:31:43,037 Initializing dataset ObjectNav-v2
2022-01-26 10:31:43,268 Initializing dataset ObjectNav-v2
2022-01-26 10:32:20,480 initializing sim Sim-v0
2022-01-26 10:32:32,073 initializing sim Sim-v0
2022-01-26 10:32:33,756 initializing sim Sim-v0
2022-01-26 10:32:34,416 initializing sim Sim-v0
2022-01-26 10:32:36,120 initializing sim Sim-v0
2022-01-26 10:32:37,448 initializing sim Sim-v0
2022-01-26 10:32:37,608 initializing sim Sim-v0
2022-01-26 10:32:37,659 initializing sim Sim-v0
2022-01-26 10:32:38,390 initializing sim Sim-v0
2022-01-26 10:32:39,252 initializing sim Sim-v0
2022-01-26 10:32:39,801 initializing sim Sim-v0
2022-01-26 10:32:41,475 initializing sim Sim-v0
2022-01-26 10:32:41,729 initializing sim Sim-v0
2022-01-26 10:32:41,865 initializing sim Sim-v0
2022-01-26 10:32:42,083 initializing sim Sim-v0
2022-01-26 10:32:42,146 initializing sim Sim-v0
2022-01-26 10:32:42,610 initializing sim Sim-v0
2022-01-26 10:32:43,194 initializing sim Sim-v0
2022-01-26 10:32:43,913 initializing sim Sim-v0
2022-01-26 10:32:44,227 initializing sim Sim-v0
2022-01-26 10:32:44,302 initializing sim Sim-v0
2022-01-26 10:32:44,921 initializing sim Sim-v0
2022-01-26 10:32:45,286 initializing sim Sim-v0
2022-01-26 10:32:46,126 initializing sim Sim-v0
2022-01-26 10:32:46,979 initializing sim Sim-v0
2022-01-26 10:32:47,252 initializing sim Sim-v0
2022-01-26 10:32:47,259 initializing sim Sim-v0
2022-01-26 10:32:47,270 initializing sim Sim-v0
2022-01-26 10:32:47,494 initializing sim Sim-v0
2022-01-26 10:32:47,885 initializing sim Sim-v0
2022-01-26 10:32:47,928 initializing sim Sim-v0
2022-01-26 10:32:48,347 initializing sim Sim-v0
2022-01-26 10:32:48,419 initializing sim Sim-v0
2022-01-26 10:32:48,785 initializing sim Sim-v0
2022-01-26 10:32:48,964 initializing sim Sim-v0
2022-01-26 10:32:49,305 initializing sim Sim-v0
2022-01-26 10:32:49,472 initializing sim Sim-v0
2022-01-26 10:32:49,982 initializing sim Sim-v0
2022-01-26 10:32:50,198 initializing sim Sim-v0
2022-01-26 10:32:50,563 initializing sim Sim-v0
2022-01-26 10:32:50,625 initializing sim Sim-v0
2022-01-26 10:32:50,765 initializing sim Sim-v0
2022-01-26 10:32:50,919 initializing sim Sim-v0
2022-01-26 10:32:51,029 initializing sim Sim-v0
2022-01-26 10:32:51,184 initializing sim Sim-v0
2022-01-26 10:32:51,211 initializing sim Sim-v0
2022-01-26 10:32:51,563 initializing sim Sim-v0
2022-01-26 10:32:51,577 initializing sim Sim-v0
2022-01-26 10:32:51,662 initializing sim Sim-v0
2022-01-26 10:32:51,683 initializing sim Sim-v0
2022-01-26 10:32:51,710 initializing sim Sim-v0
2022-01-26 10:32:52,070 initializing sim Sim-v0
2022-01-26 10:32:52,124 initializing sim Sim-v0
2022-01-26 10:32:52,484 Initializing task ObjectNav-v1
2022-01-26 10:32:53,402 initializing sim Sim-v0
2022-01-26 10:32:53,615 initializing sim Sim-v0
2022-01-26 10:32:54,100 initializing sim Sim-v0
2022-01-26 10:32:54,400 initializing sim Sim-v0
2022-01-26 10:32:54,571 initializing sim Sim-v0
2022-01-26 10:32:54,635 initializing sim Sim-v0
2022-01-26 10:32:54,649 Initializing task ObjectNav-v1
2022-01-26 10:32:55,267 Initializing task ObjectNav-v1
2022-01-26 10:32:55,369 initializing sim Sim-v0
2022-01-26 10:32:55,513 Initializing task ObjectNav-v1
2022-01-26 10:32:55,706 initializing sim Sim-v0
2022-01-26 10:32:56,342 initializing sim Sim-v0
2022-01-26 10:32:56,577 initializing sim Sim-v0
2022-01-26 10:32:56,803 initializing sim Sim-v0
2022-01-26 10:32:56,944 initializing sim Sim-v0
2022-01-26 10:32:57,351 initializing sim Sim-v0
2022-01-26 10:32:57,846 initializing sim Sim-v0
2022-01-26 10:32:57,971 Initializing task ObjectNav-v1
2022-01-26 10:32:58,661 initializing sim Sim-v0
2022-01-26 10:32:58,829 initializing sim Sim-v0
2022-01-26 10:32:58,942 Initializing task ObjectNav-v1
2022-01-26 10:32:59,212 initializing sim Sim-v0
2022-01-26 10:32:59,328 initializing sim Sim-v0
2022-01-26 10:32:59,682 Initializing task ObjectNav-v1
2022-01-26 10:32:59,729 initializing sim Sim-v0
2022-01-26 10:32:59,783 initializing sim Sim-v0
2022-01-26 10:33:00,590 Initializing task ObjectNav-v1
2022-01-26 10:33:00,602 Initializing task ObjectNav-v1
2022-01-26 10:33:01,093 initializing sim Sim-v0
2022-01-26 10:33:01,225 Initializing task ObjectNav-v1
2022-01-26 10:33:01,288 initializing sim Sim-v0
2022-01-26 10:33:01,385 initializing sim Sim-v0
2022-01-26 10:33:01,502 initializing sim Sim-v0
2022-01-26 10:33:01,524 initializing sim Sim-v0
2022-01-26 10:33:01,815 Initializing task ObjectNav-v1
2022-01-26 10:33:01,937 initializing sim Sim-v0
2022-01-26 10:33:01,999 initializing sim Sim-v0
2022-01-26 10:33:02,085 initializing sim Sim-v0
2022-01-26 10:33:02,173 Initializing task ObjectNav-v1
2022-01-26 10:33:02,498 Initializing task ObjectNav-v1
2022-01-26 10:33:02,541 initializing sim Sim-v0
2022-01-26 10:33:02,628 initializing sim Sim-v0
2022-01-26 10:33:02,654 initializing sim Sim-v0
2022-01-26 10:33:02,701 initializing sim Sim-v0
2022-01-26 10:33:02,846 initializing sim Sim-v0
2022-01-26 10:33:02,869 initializing sim Sim-v0
2022-01-26 10:33:02,902 initializing sim Sim-v0
2022-01-26 10:33:03,153 Initializing task ObjectNav-v1
2022-01-26 10:33:03,436 initializing sim Sim-v0
2022-01-26 10:33:03,494 initializing sim Sim-v0
2022-01-26 10:33:03,738 Initializing task ObjectNav-v1
2022-01-26 10:33:03,799 initializing sim Sim-v0
2022-01-26 10:33:03,985 Initializing task ObjectNav-v1
2022-01-26 10:33:04,003 initializing sim Sim-v0
2022-01-26 10:33:04,119 initializing sim Sim-v0
2022-01-26 10:33:04,351 initializing sim Sim-v0
2022-01-26 10:33:04,363 initializing sim Sim-v0
2022-01-26 10:33:04,446 initializing sim Sim-v0
2022-01-26 10:33:04,453 Initializing task ObjectNav-v1
2022-01-26 10:33:04,458 initializing sim Sim-v0
2022-01-26 10:33:04,655 Initializing task ObjectNav-v1
2022-01-26 10:33:04,851 Initializing task ObjectNav-v1
2022-01-26 10:33:04,978 Initializing task ObjectNav-v1
2022-01-26 10:33:05,315 initializing sim Sim-v0
2022-01-26 10:33:05,584 initializing sim Sim-v0
2022-01-26 10:33:06,036 initializing sim Sim-v0
2022-01-26 10:33:06,253 Initializing task ObjectNav-v1
2022-01-26 10:33:06,446 Initializing task ObjectNav-v1
2022-01-26 10:33:06,478 initializing sim Sim-v0
2022-01-26 10:33:07,100 initializing sim Sim-v0
2022-01-26 10:33:07,282 initializing sim Sim-v0
2022-01-26 10:33:07,402 initializing sim Sim-v0
2022-01-26 10:33:07,422 initializing sim Sim-v0
2022-01-26 10:33:07,603 initializing sim Sim-v0
2022-01-26 10:33:07,781 initializing sim Sim-v0
2022-01-26 10:33:07,893 initializing sim Sim-v0
2022-01-26 10:33:08,061 initializing sim Sim-v0
2022-01-26 10:33:08,341 initializing sim Sim-v0
2022-01-26 10:33:08,436 initializing sim Sim-v0
2022-01-26 10:33:08,498 initializing sim Sim-v0
2022-01-26 10:33:08,624 initializing sim Sim-v0
2022-01-26 10:33:08,667 initializing sim Sim-v0
2022-01-26 10:33:08,820 Initializing task ObjectNav-v1
2022-01-26 10:33:08,920 initializing sim Sim-v0
2022-01-26 10:33:08,932 initializing sim Sim-v0
2022-01-26 10:33:09,199 initializing sim Sim-v0
2022-01-26 10:33:09,357 Initializing task ObjectNav-v1
2022-01-26 10:33:09,793 initializing sim Sim-v0
2022-01-26 10:33:10,104 initializing sim Sim-v0
2022-01-26 10:33:10,210 Initializing task ObjectNav-v1
2022-01-26 10:33:10,523 Initializing task ObjectNav-v1
2022-01-26 10:33:10,919 initializing sim Sim-v0
2022-01-26 10:33:10,922 initializing sim Sim-v0
2022-01-26 10:33:11,084 Initializing task ObjectNav-v1
2022-01-26 10:33:11,179 Initializing task ObjectNav-v1
2022-01-26 10:33:11,188 initializing sim Sim-v0
2022-01-26 10:33:11,210 initializing sim Sim-v0
2022-01-26 10:33:11,276 initializing sim Sim-v0
2022-01-26 10:33:11,431 initializing sim Sim-v0
2022-01-26 10:33:11,433 Initializing task ObjectNav-v1
2022-01-26 10:33:11,434 initializing sim Sim-v0
2022-01-26 10:33:11,622 Initializing task ObjectNav-v1
2022-01-26 10:33:11,672 initializing sim Sim-v0
2022-01-26 10:33:11,714 initializing sim Sim-v0
2022-01-26 10:33:11,837 initializing sim Sim-v0
2022-01-26 10:33:12,693 Initializing task ObjectNav-v1
2022-01-26 10:33:12,794 initializing sim Sim-v0
2022-01-26 10:33:12,858 initializing sim Sim-v0
2022-01-26 10:33:12,920 initializing sim Sim-v0
2022-01-26 10:33:13,071 initializing sim Sim-v0
2022-01-26 10:33:13,105 initializing sim Sim-v0
2022-01-26 10:33:13,311 initializing sim Sim-v0
2022-01-26 10:33:13,413 initializing sim Sim-v0
2022-01-26 10:33:13,466 Initializing task ObjectNav-v1
2022-01-26 10:33:13,596 initializing sim Sim-v0
2022-01-26 10:33:13,736 initializing sim Sim-v0
2022-01-26 10:33:13,966 initializing sim Sim-v0
2022-01-26 10:33:13,974 Initializing task ObjectNav-v1
2022-01-26 10:33:14,020 initializing sim Sim-v0
2022-01-26 10:33:14,188 Initializing task ObjectNav-v1
2022-01-26 10:33:14,193 initializing sim Sim-v0
2022-01-26 10:33:14,237 Initializing task ObjectNav-v1
2022-01-26 10:33:14,307 initializing sim Sim-v0
2022-01-26 10:33:14,366 Initializing task ObjectNav-v1
2022-01-26 10:33:14,483 Initializing task ObjectNav-v1
2022-01-26 10:33:14,537 initializing sim Sim-v0
2022-01-26 10:33:14,926 initializing sim Sim-v0
2022-01-26 10:33:14,943 initializing sim Sim-v0
2022-01-26 10:33:14,943 Initializing task ObjectNav-v1
2022-01-26 10:33:15,134 initializing sim Sim-v0
2022-01-26 10:33:15,165 initializing sim Sim-v0
2022-01-26 10:33:15,464 Initializing task ObjectNav-v1
2022-01-26 10:33:15,478 initializing sim Sim-v0
2022-01-26 10:33:15,768 initializing sim Sim-v0
2022-01-26 10:33:15,819 Initializing task ObjectNav-v1
2022-01-26 10:33:15,913 initializing sim Sim-v0
2022-01-26 10:33:15,919 initializing sim Sim-v0
2022-01-26 10:33:15,920 initializing sim Sim-v0
2022-01-26 10:33:15,969 initializing sim Sim-v0
2022-01-26 10:33:16,009 initializing sim Sim-v0
2022-01-26 10:33:16,443 Initializing task ObjectNav-v1
2022-01-26 10:33:16,525 Initializing task ObjectNav-v1
2022-01-26 10:33:16,613 Initializing task ObjectNav-v1
2022-01-26 10:33:16,935 initializing sim Sim-v0
2022-01-26 10:33:17,032 Initializing task ObjectNav-v1
2022-01-26 10:33:17,094 initializing sim Sim-v0
2022-01-26 10:33:17,171 initializing sim Sim-v0
2022-01-26 10:33:17,207 initializing sim Sim-v0
2022-01-26 10:33:17,219 initializing sim Sim-v0
2022-01-26 10:33:17,224 initializing sim Sim-v0
2022-01-26 10:33:17,287 initializing sim Sim-v0
2022-01-26 10:33:17,566 Initializing task ObjectNav-v1
2022-01-26 10:33:17,747 initializing sim Sim-v0
2022-01-26 10:33:17,755 initializing sim Sim-v0
2022-01-26 10:33:17,791 initializing sim Sim-v0
2022-01-26 10:33:18,338 initializing sim Sim-v0
2022-01-26 10:33:18,376 initializing sim Sim-v0
2022-01-26 10:33:18,391 initializing sim Sim-v0
2022-01-26 10:33:18,471 Initializing task ObjectNav-v1
2022-01-26 10:33:18,524 initializing sim Sim-v0
2022-01-26 10:33:18,632 Initializing task ObjectNav-v1
2022-01-26 10:33:18,711 initializing sim Sim-v0
2022-01-26 10:33:18,747 initializing sim Sim-v0
2022-01-26 10:33:18,821 initializing sim Sim-v0
2022-01-26 10:33:18,864 initializing sim Sim-v0
2022-01-26 10:33:18,911 initializing sim Sim-v0
2022-01-26 10:33:18,937 initializing sim Sim-v0
2022-01-26 10:33:19,238 initializing sim Sim-v0
2022-01-26 10:33:19,282 Initializing task ObjectNav-v1
2022-01-26 10:33:19,291 initializing sim Sim-v0
2022-01-26 10:33:19,372 initializing sim Sim-v0
2022-01-26 10:33:19,412 Initializing task ObjectNav-v1
2022-01-26 10:33:19,513 initializing sim Sim-v0
2022-01-26 10:33:19,625 Initializing task ObjectNav-v1
2022-01-26 10:33:19,679 initializing sim Sim-v0
2022-01-26 10:33:20,089 Initializing task ObjectNav-v1
2022-01-26 10:33:20,129 initializing sim Sim-v0
2022-01-26 10:33:20,340 Initializing task ObjectNav-v1
2022-01-26 10:33:20,342 initializing sim Sim-v0
2022-01-26 10:33:20,351 initializing sim Sim-v0
2022-01-26 10:33:20,545 initializing sim Sim-v0
2022-01-26 10:33:20,582 Initializing task ObjectNav-v1
2022-01-26 10:33:20,602 initializing sim Sim-v0
2022-01-26 10:33:20,718 initializing sim Sim-v0
2022-01-26 10:33:20,761 Initializing task ObjectNav-v1
2022-01-26 10:33:20,808 initializing sim Sim-v0
2022-01-26 10:33:20,930 initializing sim Sim-v0
2022-01-26 10:33:21,090 initializing sim Sim-v0
2022-01-26 10:33:21,117 initializing sim Sim-v0
2022-01-26 10:33:21,156 Initializing task ObjectNav-v1
2022-01-26 10:33:21,171 Initializing task ObjectNav-v1
2022-01-26 10:33:21,286 Initializing task ObjectNav-v1
2022-01-26 10:33:21,327 initializing sim Sim-v0
2022-01-26 10:33:21,336 initializing sim Sim-v0
2022-01-26 10:33:21,462 initializing sim Sim-v0
2022-01-26 10:33:21,521 initializing sim Sim-v0
2022-01-26 10:33:21,526 initializing sim Sim-v0
2022-01-26 10:33:21,573 initializing sim Sim-v0
2022-01-26 10:33:21,619 Initializing task ObjectNav-v1
2022-01-26 10:33:21,637 Initializing task ObjectNav-v1
2022-01-26 10:33:21,823 initializing sim Sim-v0
2022-01-26 10:33:21,979 Initializing task ObjectNav-v1
2022-01-26 10:33:22,009 initializing sim Sim-v0
2022-01-26 10:33:22,039 initializing sim Sim-v0
2022-01-26 10:33:22,080 initializing sim Sim-v0
2022-01-26 10:33:22,128 initializing sim Sim-v0
2022-01-26 10:33:22,168 initializing sim Sim-v0
2022-01-26 10:33:22,214 Initializing task ObjectNav-v1
2022-01-26 10:33:22,258 initializing sim Sim-v0
2022-01-26 10:33:22,276 initializing sim Sim-v0
2022-01-26 10:33:22,393 initializing sim Sim-v0
2022-01-26 10:33:22,427 initializing sim Sim-v0
2022-01-26 10:33:22,557 initializing sim Sim-v0
2022-01-26 10:33:22,585 initializing sim Sim-v0
2022-01-26 10:33:22,715 Initializing task ObjectNav-v1
2022-01-26 10:33:22,732 initializing sim Sim-v0
2022-01-26 10:33:22,779 initializing sim Sim-v0
2022-01-26 10:33:22,798 initializing sim Sim-v0
2022-01-26 10:33:22,822 initializing sim Sim-v0
2022-01-26 10:33:22,882 initializing sim Sim-v0
2022-01-26 10:33:23,029 initializing sim Sim-v0
2022-01-26 10:33:23,139 initializing sim Sim-v0
2022-01-26 10:33:23,197 initializing sim Sim-v0
2022-01-26 10:33:23,228 initializing sim Sim-v0
2022-01-26 10:33:23,405 Initializing task ObjectNav-v1
2022-01-26 10:33:23,441 initializing sim Sim-v0
2022-01-26 10:33:23,448 initializing sim Sim-v0
2022-01-26 10:33:23,497 initializing sim Sim-v0
2022-01-26 10:33:23,511 initializing sim Sim-v0
2022-01-26 10:33:23,569 initializing sim Sim-v0
2022-01-26 10:33:23,709 Initializing task ObjectNav-v1
2022-01-26 10:33:23,723 Initializing task ObjectNav-v1
2022-01-26 10:33:23,795 Initializing task ObjectNav-v1
2022-01-26 10:33:23,843 initializing sim Sim-v0
2022-01-26 10:33:23,945 [ train_loader has [5009, 5421, 5135, 5071, 4745, 5141, 4543, 4926] samples ]
2022-01-26 10:33:23,948 obs transforms: []
2022-01-26 10:33:24,092 initializing sim Sim-v0
2022-01-26 10:33:24,097 initializing sim Sim-v0
2022-01-26 10:33:24,108 initializing sim Sim-v0
2022-01-26 10:33:24,137 initializing sim Sim-v0
2022-01-26 10:33:24,252 Initializing task ObjectNav-v1
2022-01-26 10:33:24,344 Not setting up goal seg
2022-01-26 10:33:24,365 Initializing task ObjectNav-v1
2022-01-26 10:33:24,380 Setting up Sem Seg model
2022-01-26 10:33:24,380 

Setting up GPS sensor
2022-01-26 10:33:24,381 

Setting up Compass sensor
2022-01-26 10:33:24,381 

Setting up Object Goal sensor
2022-01-26 10:33:24,407 initializing sim Sim-v0
2022-01-26 10:33:24,439 initializing sim Sim-v0
2022-01-26 10:33:24,510 initializing sim Sim-v0
2022-01-26 10:33:24,560 initializing sim Sim-v0
2022-01-26 10:33:24,574 initializing sim Sim-v0
2022-01-26 10:33:24,575 [ train_loader has [5201, 5414, 3918, 4468, 5167, 4873, 5692, 5258] samples ]
2022-01-26 10:33:24,578 obs transforms: []
2022-01-26 10:33:24,623 initializing sim Sim-v0
2022-01-26 10:33:24,685 initializing sim Sim-v0
2022-01-26 10:33:24,765 initializing sim Sim-v0
2022-01-26 10:33:24,874 Not setting up goal seg
2022-01-26 10:33:24,908 Setting up Sem Seg model
2022-01-26 10:33:24,909 

Setting up GPS sensor
2022-01-26 10:33:24,909 

Setting up Compass sensor
2022-01-26 10:33:24,909 

Setting up Object Goal sensor
2022-01-26 10:33:24,984 initializing sim Sim-v0
2022-01-26 10:33:25,232 initializing sim Sim-v0
2022-01-26 10:33:25,306 initializing sim Sim-v0
2022-01-26 10:33:25,379 initializing sim Sim-v0
2022-01-26 10:33:25,389 initializing sim Sim-v0
2022-01-26 10:33:25,509 initializing sim Sim-v0
2022-01-26 10:33:25,681 initializing sim Sim-v0
2022-01-26 10:33:25,688 initializing sim Sim-v0
2022-01-26 10:33:25,709 Initializing task ObjectNav-v1
2022-01-26 10:33:25,764 initializing sim Sim-v0
2022-01-26 10:33:25,892 initializing sim Sim-v0
2022-01-26 10:33:25,968 initializing sim Sim-v0
2022-01-26 10:33:26,014 initializing sim Sim-v0
2022-01-26 10:33:26,096 Initializing task ObjectNav-v1
2022-01-26 10:33:26,106 initializing sim Sim-v0
2022-01-26 10:33:26,124 initializing sim Sim-v0
2022-01-26 10:33:26,172 Initializing task ObjectNav-v1
2022-01-26 10:33:26,239 initializing sim Sim-v0
2022-01-26 10:33:26,354 initializing sim Sim-v0
2022-01-26 10:33:26,424 initializing sim Sim-v0
2022-01-26 10:33:26,539 initializing sim Sim-v0
2022-01-26 10:33:26,581 initializing sim Sim-v0
2022-01-26 10:33:26,591 initializing sim Sim-v0
2022-01-26 10:33:26,606 initializing sim Sim-v0
2022-01-26 10:33:26,618 initializing sim Sim-v0
2022-01-26 10:33:26,667 initializing sim Sim-v0
2022-01-26 10:33:26,674 initializing sim Sim-v0
2022-01-26 10:33:26,701 Initializing task ObjectNav-v1
2022-01-26 10:33:26,816 initializing sim Sim-v0
2022-01-26 10:33:26,844 initializing sim Sim-v0
2022-01-26 10:33:26,935 initializing sim Sim-v0
2022-01-26 10:33:26,939 initializing sim Sim-v0
2022-01-26 10:33:26,988 initializing sim Sim-v0
2022-01-26 10:33:27,026 Initializing task ObjectNav-v1
2022-01-26 10:33:27,083 initializing sim Sim-v0
2022-01-26 10:33:27,131 initializing sim Sim-v0
2022-01-26 10:33:27,134 initializing sim Sim-v0
2022-01-26 10:33:27,213 initializing sim Sim-v0
2022-01-26 10:33:27,218 initializing sim Sim-v0
2022-01-26 10:33:27,446 initializing sim Sim-v0
2022-01-26 10:33:27,582 initializing sim Sim-v0
2022-01-26 10:33:27,605 initializing sim Sim-v0
2022-01-26 10:33:27,610 Initializing task ObjectNav-v1
2022-01-26 10:33:27,627 initializing sim Sim-v0
2022-01-26 10:33:27,676 initializing sim Sim-v0
2022-01-26 10:33:28,014 initializing sim Sim-v0
2022-01-26 10:33:28,134 Initializing task ObjectNav-v1
2022-01-26 10:33:28,213 Initializing task ObjectNav-v1
2022-01-26 10:33:28,294 initializing sim Sim-v0
2022-01-26 10:33:28,365 initializing sim Sim-v0
2022-01-26 10:33:28,384 Initializing task ObjectNav-v1
2022-01-26 10:33:28,415 Initializing task ObjectNav-v1
2022-01-26 10:33:28,464 initializing sim Sim-v0
2022-01-26 10:33:28,518 initializing sim Sim-v0
2022-01-26 10:33:28,574 initializing sim Sim-v0
2022-01-26 10:33:28,668 initializing sim Sim-v0
2022-01-26 10:33:28,690 Initializing task ObjectNav-v1
2022-01-26 10:33:28,692 initializing sim Sim-v0
2022-01-26 10:33:28,696 Initializing task ObjectNav-v1
2022-01-26 10:33:28,702 initializing sim Sim-v0
2022-01-26 10:33:28,721 initializing sim Sim-v0
2022-01-26 10:33:28,742 initializing sim Sim-v0
2022-01-26 10:33:28,881 initializing sim Sim-v0
2022-01-26 10:33:28,893 initializing sim Sim-v0
2022-01-26 10:33:28,930 initializing sim Sim-v0
2022-01-26 10:33:29,014 initializing sim Sim-v0
2022-01-26 10:33:29,195 initializing sim Sim-v0
2022-01-26 10:33:29,204 initializing sim Sim-v0
2022-01-26 10:33:29,364 [ train_loader has [5460, 5058, 4885, 4553, 4902, 4516, 5535, 5082] samples ]
2022-01-26 10:33:29,366 obs transforms: []
2022-01-26 10:33:29,434 initializing sim Sim-v0
2022-01-26 10:33:29,501 initializing sim Sim-v0
2022-01-26 10:33:29,551 initializing sim Sim-v0
2022-01-26 10:33:29,572 Initializing task ObjectNav-v1
2022-01-26 10:33:29,607 initializing sim Sim-v0
2022-01-26 10:33:29,673 Not setting up goal seg
2022-01-26 10:33:29,709 Setting up Sem Seg model
2022-01-26 10:33:29,709 

Setting up GPS sensor
2022-01-26 10:33:29,709 

Setting up Compass sensor
2022-01-26 10:33:29,709 

Setting up Object Goal sensor
2022-01-26 10:33:29,714 initializing sim Sim-v0
2022-01-26 10:33:29,764 initializing sim Sim-v0
2022-01-26 10:33:29,781 Initializing task ObjectNav-v1
2022-01-26 10:33:29,804 initializing sim Sim-v0
2022-01-26 10:33:29,941 initializing sim Sim-v0
2022-01-26 10:33:30,115 initializing sim Sim-v0
2022-01-26 10:33:30,210 initializing sim Sim-v0
2022-01-26 10:33:30,267 initializing sim Sim-v0
2022-01-26 10:33:30,378 initializing sim Sim-v0
2022-01-26 10:33:30,437 initializing sim Sim-v0
2022-01-26 10:33:30,446 Initializing task ObjectNav-v1
2022-01-26 10:33:30,479 initializing sim Sim-v0
2022-01-26 10:33:30,540 initializing sim Sim-v0
2022-01-26 10:33:30,692 [ train_loader has [5762, 4738, 4511, 4994, 5274, 5313, 4632, 4767] samples ]
2022-01-26 10:33:30,694 obs transforms: []
2022-01-26 10:33:30,699 initializing sim Sim-v0
2022-01-26 10:33:30,858 initializing sim Sim-v0
2022-01-26 10:33:30,904 initializing sim Sim-v0
2022-01-26 10:33:30,917 initializing sim Sim-v0
2022-01-26 10:33:30,972 initializing sim Sim-v0
2022-01-26 10:33:30,994 initializing sim Sim-v0
2022-01-26 10:33:31,010 Initializing task ObjectNav-v1
2022-01-26 10:33:31,031 Not setting up goal seg
2022-01-26 10:33:31,044 initializing sim Sim-v0
2022-01-26 10:33:31,068 Setting up Sem Seg model
2022-01-26 10:33:31,068 

Setting up GPS sensor
2022-01-26 10:33:31,068 

Setting up Compass sensor
2022-01-26 10:33:31,068 

Setting up Object Goal sensor
2022-01-26 10:33:31,171 initializing sim Sim-v0
2022-01-26 10:33:31,222 initializing sim Sim-v0
2022-01-26 10:33:31,283 initializing sim Sim-v0
2022-01-26 10:33:31,350 initializing sim Sim-v0
2022-01-26 10:33:31,423 initializing sim Sim-v0
2022-01-26 10:33:31,497 initializing sim Sim-v0
2022-01-26 10:33:31,527 Initializing task ObjectNav-v1
2022-01-26 10:33:31,592 initializing sim Sim-v0
2022-01-26 10:33:31,672 initializing sim Sim-v0
2022-01-26 10:33:31,674 initializing sim Sim-v0
2022-01-26 10:33:31,710 initializing sim Sim-v0
2022-01-26 10:33:31,736 initializing sim Sim-v0
2022-01-26 10:33:31,799 initializing sim Sim-v0
2022-01-26 10:33:31,935 initializing sim Sim-v0
2022-01-26 10:33:32,068 initializing sim Sim-v0
2022-01-26 10:33:32,391 initializing sim Sim-v0
2022-01-26 10:33:32,415 initializing sim Sim-v0
2022-01-26 10:33:32,457 initializing sim Sim-v0
2022-01-26 10:33:32,557 initializing sim Sim-v0
2022-01-26 10:33:32,574 initializing sim Sim-v0
2022-01-26 10:33:32,578 initializing sim Sim-v0
2022-01-26 10:33:32,652 initializing sim Sim-v0
2022-01-26 10:33:32,662 initializing sim Sim-v0
2022-01-26 10:33:32,725 initializing sim Sim-v0
2022-01-26 10:33:32,754 Initializing task ObjectNav-v1
2022-01-26 10:33:32,835 initializing sim Sim-v0
2022-01-26 10:33:32,923 Initializing task ObjectNav-v1
2022-01-26 10:33:32,983 initializing sim Sim-v0
2022-01-26 10:33:33,060 Initializing task ObjectNav-v1
2022-01-26 10:33:33,074 initializing sim Sim-v0
2022-01-26 10:33:33,203 initializing sim Sim-v0
2022-01-26 10:33:33,256 initializing sim Sim-v0
2022-01-26 10:33:33,405 initializing sim Sim-v0
2022-01-26 10:33:33,470 initializing sim Sim-v0
2022-01-26 10:33:33,509 initializing sim Sim-v0
2022-01-26 10:33:33,525 initializing sim Sim-v0
2022-01-26 10:33:33,636 initializing sim Sim-v0
2022-01-26 10:33:33,670 initializing sim Sim-v0
2022-01-26 10:33:33,729 initializing sim Sim-v0
2022-01-26 10:33:33,912 initializing sim Sim-v0
2022-01-26 10:33:34,124 initializing sim Sim-v0
2022-01-26 10:33:34,240 initializing sim Sim-v0
2022-01-26 10:33:34,318 initializing sim Sim-v0
2022-01-26 10:33:34,329 Initializing task ObjectNav-v1
2022-01-26 10:33:34,441 initializing sim Sim-v0
2022-01-26 10:33:34,515 initializing sim Sim-v0
2022-01-26 10:33:34,589 initializing sim Sim-v0
2022-01-26 10:33:34,654 initializing sim Sim-v0
2022-01-26 10:33:34,691 Initializing task ObjectNav-v1
2022-01-26 10:33:34,811 Initializing task ObjectNav-v1
2022-01-26 10:33:34,815 Initializing task ObjectNav-v1
2022-01-26 10:33:34,854 initializing sim Sim-v0
2022-01-26 10:33:34,873 Initializing task ObjectNav-v1
2022-01-26 10:33:34,873 initializing sim Sim-v0
2022-01-26 10:33:34,899 initializing sim Sim-v0
2022-01-26 10:33:34,909 initializing sim Sim-v0
2022-01-26 10:33:34,981 initializing sim Sim-v0
2022-01-26 10:33:35,027 initializing sim Sim-v0
2022-01-26 10:33:35,060 initializing sim Sim-v0
2022-01-26 10:33:35,075 [ train_loader has [5611, 5273, 4767, 5096, 4605, 5195, 4429, 5015] samples ]
2022-01-26 10:33:35,077 obs transforms: []
2022-01-26 10:33:35,099 initializing sim Sim-v0
2022-01-26 10:33:35,171 initializing sim Sim-v0
2022-01-26 10:33:35,267 initializing sim Sim-v0
2022-01-26 10:33:35,292 initializing sim Sim-v0
2022-01-26 10:33:35,331 Initializing task ObjectNav-v1
2022-01-26 10:33:35,347 initializing sim Sim-v0
2022-01-26 10:33:35,347 initializing sim Sim-v0
2022-01-26 10:33:35,387 Initializing task ObjectNav-v1
2022-01-26 10:33:35,401 Not setting up goal seg
2022-01-26 10:33:35,436 Setting up Sem Seg model
2022-01-26 10:33:35,436 

Setting up GPS sensor
2022-01-26 10:33:35,436 

Setting up Compass sensor
2022-01-26 10:33:35,437 

Setting up Object Goal sensor
2022-01-26 10:33:35,454 initializing sim Sim-v0
2022-01-26 10:33:35,464 initializing sim Sim-v0
2022-01-26 10:33:35,502 Initializing task ObjectNav-v1
2022-01-26 10:33:35,650 initializing sim Sim-v0
2022-01-26 10:33:35,699 initializing sim Sim-v0
2022-01-26 10:33:35,701 initializing sim Sim-v0
2022-01-26 10:33:35,764 initializing sim Sim-v0
2022-01-26 10:33:35,789 initializing sim Sim-v0
2022-01-26 10:33:35,849 initializing sim Sim-v0
2022-01-26 10:33:35,882 [ train_loader has [5484, 5013, 5215, 5372, 4736, 4064, 5785, 4322] samples ]
2022-01-26 10:33:35,885 obs transforms: []
2022-01-26 10:33:36,012 initializing sim Sim-v0
2022-01-26 10:33:36,065 initializing sim Sim-v0
2022-01-26 10:33:36,119 Initializing task ObjectNav-v1
2022-01-26 10:33:36,140 initializing sim Sim-v0
2022-01-26 10:33:36,234 Not setting up goal seg
2022-01-26 10:33:36,268 Setting up Sem Seg model
2022-01-26 10:33:36,269 

Setting up GPS sensor
2022-01-26 10:33:36,269 

Setting up Compass sensor
2022-01-26 10:33:36,269 

Setting up Object Goal sensor
2022-01-26 10:33:36,330 initializing sim Sim-v0
2022-01-26 10:33:36,788 initializing sim Sim-v0
2022-01-26 10:33:36,806 initializing sim Sim-v0
2022-01-26 10:33:36,826 initializing sim Sim-v0
2022-01-26 10:33:36,973 initializing sim Sim-v0
2022-01-26 10:33:37,034 initializing sim Sim-v0
2022-01-26 10:33:37,072 initializing sim Sim-v0
2022-01-26 10:33:37,220 Initializing task ObjectNav-v1
2022-01-26 10:33:37,259 initializing sim Sim-v0
2022-01-26 10:33:37,336 initializing sim Sim-v0
2022-01-26 10:33:37,388 initializing sim Sim-v0
2022-01-26 10:33:37,451 Initializing task ObjectNav-v1
2022-01-26 10:33:37,461 initializing sim Sim-v0
2022-01-26 10:33:37,546 initializing sim Sim-v0
2022-01-26 10:33:37,597 initializing sim Sim-v0
2022-01-26 10:33:37,616 initializing sim Sim-v0
2022-01-26 10:33:37,824 initializing sim Sim-v0
2022-01-26 10:33:37,844 initializing sim Sim-v0
2022-01-26 10:33:37,862 initializing sim Sim-v0
2022-01-26 10:33:37,876 initializing sim Sim-v0
2022-01-26 10:33:37,925 initializing sim Sim-v0
2022-01-26 10:33:37,991 initializing sim Sim-v0
2022-01-26 10:33:38,027 initializing sim Sim-v0
2022-01-26 10:33:38,061 initializing sim Sim-v0
2022-01-26 10:33:38,170 initializing sim Sim-v0
2022-01-26 10:33:38,207 initializing sim Sim-v0
2022-01-26 10:33:38,208 initializing sim Sim-v0
2022-01-26 10:33:38,273 initializing sim Sim-v0
2022-01-26 10:33:38,286 Initializing task ObjectNav-v1
2022-01-26 10:33:38,372 initializing sim Sim-v0
2022-01-26 10:33:38,420 initializing sim Sim-v0
2022-01-26 10:33:38,457 initializing sim Sim-v0
2022-01-26 10:33:38,499 Initializing task ObjectNav-v1
2022-01-26 10:33:38,531 initializing sim Sim-v0
2022-01-26 10:33:38,707 initializing sim Sim-v0
2022-01-26 10:33:38,727 initializing sim Sim-v0
2022-01-26 10:33:38,852 initializing sim Sim-v0
2022-01-26 10:33:38,983 initializing sim Sim-v0
2022-01-26 10:33:39,012 Initializing task ObjectNav-v1
2022-01-26 10:33:39,142 initializing sim Sim-v0
2022-01-26 10:33:39,188 initializing sim Sim-v0
2022-01-26 10:33:39,256 Initializing task ObjectNav-v1
2022-01-26 10:33:39,443 initializing sim Sim-v0
2022-01-26 10:33:39,624 initializing sim Sim-v0
2022-01-26 10:33:39,626 Initializing task ObjectNav-v1
2022-01-26 10:33:39,645 initializing sim Sim-v0
2022-01-26 10:33:39,650 Initializing task ObjectNav-v1
2022-01-26 10:33:39,739 initializing sim Sim-v0
2022-01-26 10:33:39,793 initializing sim Sim-v0
2022-01-26 10:33:39,912 initializing sim Sim-v0
2022-01-26 10:33:39,982 initializing sim Sim-v0
2022-01-26 10:33:40,014 initializing sim Sim-v0
2022-01-26 10:33:40,110 initializing sim Sim-v0
2022-01-26 10:33:40,177 Initializing task ObjectNav-v1
2022-01-26 10:33:40,221 Initializing task ObjectNav-v1
2022-01-26 10:33:40,418 [ train_loader has [4728, 4759, 4739, 5747, 5514, 4657, 4208, 5639] samples ]
2022-01-26 10:33:40,421 obs transforms: []
2022-01-26 10:33:40,461 Initializing task ObjectNav-v1
2022-01-26 10:33:40,647 initializing sim Sim-v0
2022-01-26 10:33:40,737 initializing sim Sim-v0
2022-01-26 10:33:40,755 Not setting up goal seg
2022-01-26 10:33:40,774 initializing sim Sim-v0
2022-01-26 10:33:40,789 Setting up Sem Seg model
2022-01-26 10:33:40,789 

Setting up GPS sensor
2022-01-26 10:33:40,789 

Setting up Compass sensor
2022-01-26 10:33:40,790 

Setting up Object Goal sensor
2022-01-26 10:33:40,912 initializing sim Sim-v0
2022-01-26 10:33:40,991 initializing sim Sim-v0
2022-01-26 10:33:41,129 initializing sim Sim-v0
2022-01-26 10:33:41,181 initializing sim Sim-v0
2022-01-26 10:33:41,199 initializing sim Sim-v0
2022-01-26 10:33:41,243 initializing sim Sim-v0
2022-01-26 10:33:41,280 Initializing task ObjectNav-v1
2022-01-26 10:33:41,291 initializing sim Sim-v0
2022-01-26 10:33:41,433 initializing sim Sim-v0
2022-01-26 10:33:41,444 Initializing task ObjectNav-v1
2022-01-26 10:33:41,594 initializing sim Sim-v0
2022-01-26 10:33:41,620 initializing sim Sim-v0
2022-01-26 10:33:41,987 initializing sim Sim-v0
2022-01-26 10:33:41,987 Initializing task ObjectNav-v1
2022-01-26 10:33:42,019 initializing sim Sim-v0
2022-01-26 10:33:42,072 Initializing task ObjectNav-v1
2022-01-26 10:33:42,123 Initializing task ObjectNav-v1
2022-01-26 10:33:42,187 initializing sim Sim-v0
2022-01-26 10:33:42,189 Initializing task ObjectNav-v1
2022-01-26 10:33:42,256 [ train_loader has [4730, 5555, 5767, 5459, 4639, 5273, 4295, 4273] samples ]
2022-01-26 10:33:42,258 obs transforms: []
2022-01-26 10:33:42,277 initializing sim Sim-v0
2022-01-26 10:33:42,339 initializing sim Sim-v0
2022-01-26 10:33:42,342 initializing sim Sim-v0
2022-01-26 10:33:42,348 Initializing task ObjectNav-v1
2022-01-26 10:33:42,484 Initializing task ObjectNav-v1
2022-01-26 10:33:42,497 initializing sim Sim-v0
2022-01-26 10:33:42,510 initializing sim Sim-v0
2022-01-26 10:33:42,598 Not setting up goal seg
2022-01-26 10:33:42,611 Initializing task ObjectNav-v1
2022-01-26 10:33:42,631 Setting up Sem Seg model
2022-01-26 10:33:42,631 

Setting up GPS sensor
2022-01-26 10:33:42,631 

Setting up Compass sensor
2022-01-26 10:33:42,632 

Setting up Object Goal sensor
2022-01-26 10:33:42,659 Initializing task ObjectNav-v1
2022-01-26 10:33:42,661 initializing sim Sim-v0
2022-01-26 10:33:42,674 initializing sim Sim-v0
2022-01-26 10:33:42,770 initializing sim Sim-v0
2022-01-26 10:33:42,797 Initializing task ObjectNav-v1
2022-01-26 10:33:42,823 Initializing task ObjectNav-v1
2022-01-26 10:33:42,952 initializing sim Sim-v0
2022-01-26 10:33:42,958 initializing sim Sim-v0
2022-01-26 10:33:42,996 Initializing task ObjectNav-v1
2022-01-26 10:33:43,093 initializing sim Sim-v0
2022-01-26 10:33:43,219 initializing sim Sim-v0
2022-01-26 10:33:43,367 Initializing task ObjectNav-v1
2022-01-26 10:33:43,401 initializing sim Sim-v0
2022-01-26 10:33:43,502 initializing sim Sim-v0
2022-01-26 10:33:43,523 initializing sim Sim-v0
2022-01-26 10:33:43,602 Initializing task ObjectNav-v1
2022-01-26 10:33:43,716 Initializing task ObjectNav-v1
2022-01-26 10:33:43,773 initializing sim Sim-v0
2022-01-26 10:33:43,905 initializing sim Sim-v0
2022-01-26 10:33:44,044 initializing sim Sim-v0
2022-01-26 10:33:44,133 initializing sim Sim-v0
2022-01-26 10:33:44,157 initializing sim Sim-v0
2022-01-26 10:33:44,160 initializing sim Sim-v0
2022-01-26 10:33:44,179 Initializing task ObjectNav-v1
2022-01-26 10:33:44,240 initializing sim Sim-v0
2022-01-26 10:33:44,301 initializing sim Sim-v0
2022-01-26 10:33:44,335 initializing sim Sim-v0
2022-01-26 10:33:44,402 initializing sim Sim-v0
2022-01-26 10:33:44,460 Initializing task ObjectNav-v1
2022-01-26 10:33:44,585 Initializing task ObjectNav-v1
2022-01-26 10:33:44,609 initializing sim Sim-v0
2022-01-26 10:33:44,705 initializing sim Sim-v0
2022-01-26 10:33:44,926 Initializing task ObjectNav-v1
2022-01-26 10:33:45,369 initializing sim Sim-v0
2022-01-26 10:33:45,620 Initializing task ObjectNav-v1
2022-01-26 10:33:45,741 initializing sim Sim-v0
2022-01-26 10:33:45,806 initializing sim Sim-v0
2022-01-26 10:33:45,871 Initializing task ObjectNav-v1
2022-01-26 10:33:45,944 initializing sim Sim-v0
2022-01-26 10:33:46,004 Initializing task ObjectNav-v1
2022-01-26 10:33:46,058 Initializing task ObjectNav-v1
2022-01-26 10:33:46,099 Initializing task ObjectNav-v1
2022-01-26 10:33:46,345 initializing sim Sim-v0
2022-01-26 10:33:46,361 Initializing task ObjectNav-v1
2022-01-26 10:33:46,506 Initializing task ObjectNav-v1
2022-01-26 10:33:46,656 Initializing task ObjectNav-v1
2022-01-26 10:33:46,670 initializing sim Sim-v0
2022-01-26 10:33:46,765 initializing sim Sim-v0
2022-01-26 10:33:46,808 initializing sim Sim-v0
2022-01-26 10:33:46,896 Initializing task ObjectNav-v1
2022-01-26 10:33:47,016 initializing sim Sim-v0
2022-01-26 10:33:47,197 Initializing task ObjectNav-v1
2022-01-26 10:33:47,310 Initializing task ObjectNav-v1
2022-01-26 10:33:47,383 initializing sim Sim-v0
2022-01-26 10:33:47,498 initializing sim Sim-v0
2022-01-26 10:33:47,554 Initializing task ObjectNav-v1
2022-01-26 10:33:47,573 Initializing task ObjectNav-v1
2022-01-26 10:33:47,621 Initializing task ObjectNav-v1
2022-01-26 10:33:47,759 Initializing task ObjectNav-v1
2022-01-26 10:33:47,826 Initializing task ObjectNav-v1
2022-01-26 10:33:47,838 Initializing task ObjectNav-v1
2022-01-26 10:33:48,082 Initializing task ObjectNav-v1
2022-01-26 10:33:48,660 Initializing task ObjectNav-v1
2022-01-26 10:33:48,672 initializing sim Sim-v0
2022-01-26 10:33:48,672 initializing sim Sim-v0
2022-01-26 10:33:48,738 Initializing task ObjectNav-v1
2022-01-26 10:33:48,750 initializing sim Sim-v0
2022-01-26 10:33:48,947 initializing sim Sim-v0
2022-01-26 10:33:49,123 Initializing task ObjectNav-v1
2022-01-26 10:33:49,414 Initializing task ObjectNav-v1
2022-01-26 10:33:49,433 initializing sim Sim-v0
2022-01-26 10:33:49,504 Initializing task ObjectNav-v1
2022-01-26 10:33:49,561 initializing sim Sim-v0
2022-01-26 10:33:49,639 Initializing task ObjectNav-v1
2022-01-26 10:33:49,819 Initializing task ObjectNav-v1
2022-01-26 10:33:49,865 initializing sim Sim-v0
2022-01-26 10:33:49,978 Initializing task ObjectNav-v1
2022-01-26 10:33:50,184 Initializing task ObjectNav-v1
2022-01-26 10:33:50,270 Initializing task ObjectNav-v1
2022-01-26 10:33:50,346 initializing sim Sim-v0
2022-01-26 10:33:50,356 initializing sim Sim-v0
2022-01-26 10:33:50,358 initializing sim Sim-v0
2022-01-26 10:33:50,370 initializing sim Sim-v0
2022-01-26 10:33:50,699 Initializing task ObjectNav-v1
2022-01-26 10:33:50,740 Initializing task ObjectNav-v1
2022-01-26 10:33:50,755 initializing sim Sim-v0
2022-01-26 10:33:50,784 Initializing task ObjectNav-v1
2022-01-26 10:33:50,900 Initializing task ObjectNav-v1
2022-01-26 10:33:50,914 Initializing task ObjectNav-v1
2022-01-26 10:33:51,028 initializing sim Sim-v0
2022-01-26 10:33:51,258 Initializing task ObjectNav-v1
2022-01-26 10:33:51,278 Initializing task ObjectNav-v1
2022-01-26 10:33:51,453 Initializing task ObjectNav-v1
2022-01-26 10:33:51,459 initializing sim Sim-v0
2022-01-26 10:33:51,485 initializing sim Sim-v0
2022-01-26 10:33:51,496 Initializing task ObjectNav-v1
2022-01-26 10:33:51,551 Initializing task ObjectNav-v1
2022-01-26 10:33:51,694 Initializing task ObjectNav-v1
2022-01-26 10:33:51,780 initializing sim Sim-v0
2022-01-26 10:33:51,813 Initializing task ObjectNav-v1
2022-01-26 10:33:51,928 Initializing task ObjectNav-v1
2022-01-26 10:33:52,051 initializing sim Sim-v0
2022-01-26 10:33:52,135 Initializing task ObjectNav-v1
2022-01-26 10:33:52,488 Initializing task ObjectNav-v1
2022-01-26 10:33:52,595 initializing sim Sim-v0
2022-01-26 10:33:52,644 Initializing task ObjectNav-v1
2022-01-26 10:33:52,884 Initializing task ObjectNav-v1
2022-01-26 10:33:52,922 initializing sim Sim-v0
2022-01-26 10:33:52,954 Initializing task ObjectNav-v1
2022-01-26 10:33:53,062 initializing sim Sim-v0
2022-01-26 10:33:53,147 Initializing task ObjectNav-v1
2022-01-26 10:33:53,227 Initializing task ObjectNav-v1
2022-01-26 10:33:53,459 Initializing task ObjectNav-v1
2022-01-26 10:33:53,474 Initializing task ObjectNav-v1
2022-01-26 10:33:53,492 Initializing task ObjectNav-v1
2022-01-26 10:33:53,508 Initializing task ObjectNav-v1
2022-01-26 10:33:53,653 Initializing task ObjectNav-v1
2022-01-26 10:33:53,850 Initializing task ObjectNav-v1
2022-01-26 10:33:53,922 Initializing task ObjectNav-v1
2022-01-26 10:33:53,929 Initializing task ObjectNav-v1
2022-01-26 10:33:53,948 initializing sim Sim-v0
2022-01-26 10:33:53,986 Initializing task ObjectNav-v1
2022-01-26 10:33:54,047 Initializing task ObjectNav-v1
2022-01-26 10:33:54,229 Initializing task ObjectNav-v1
2022-01-26 10:33:54,309 initializing sim Sim-v0
2022-01-26 10:33:54,555 Initializing task ObjectNav-v1
2022-01-26 10:33:54,635 initializing sim Sim-v0
2022-01-26 10:33:54,925 Initializing task ObjectNav-v1
2022-01-26 10:33:55,078 initializing sim Sim-v0
2022-01-26 10:33:55,207 Initializing task ObjectNav-v1
2022-01-26 10:33:55,268 Initializing task ObjectNav-v1
2022-01-26 10:33:55,276 Initializing task ObjectNav-v1
2022-01-26 10:33:55,336 Initializing task ObjectNav-v1
2022-01-26 10:33:55,417 Initializing task ObjectNav-v1
2022-01-26 10:33:55,444 Initializing task ObjectNav-v1
2022-01-26 10:33:55,633 Initializing task ObjectNav-v1
2022-01-26 10:33:55,720 Initializing task ObjectNav-v1
2022-01-26 10:33:55,762 Initializing task ObjectNav-v1
2022-01-26 10:33:55,960 Initializing task ObjectNav-v1
2022-01-26 10:33:55,964 Initializing task ObjectNav-v1
2022-01-26 10:33:55,986 Initializing task ObjectNav-v1
2022-01-26 10:33:56,156 Initializing task ObjectNav-v1
2022-01-26 10:33:56,237 Initializing task ObjectNav-v1
2022-01-26 10:33:56,438 Initializing task ObjectNav-v1
2022-01-26 10:33:56,536 Initializing task ObjectNav-v1
2022-01-26 10:33:56,913 Initializing task ObjectNav-v1
2022-01-26 10:33:56,930 initializing sim Sim-v0
2022-01-26 10:33:56,980 Initializing task ObjectNav-v1
2022-01-26 10:33:57,047 Initializing task ObjectNav-v1
2022-01-26 10:33:57,166 Initializing task ObjectNav-v1
2022-01-26 10:33:57,182 Initializing task ObjectNav-v1
2022-01-26 10:33:57,191 Initializing task ObjectNav-v1
2022-01-26 10:33:57,428 Initializing task ObjectNav-v1
2022-01-26 10:33:57,548 Initializing task ObjectNav-v1
2022-01-26 10:33:57,632 initializing sim Sim-v0
2022-01-26 10:33:57,715 Initializing task ObjectNav-v1
2022-01-26 10:33:57,804 Initializing task ObjectNav-v1
2022-01-26 10:33:57,829 Initializing task ObjectNav-v1
2022-01-26 10:33:58,264 Initializing task ObjectNav-v1
2022-01-26 10:33:58,400 Initializing task ObjectNav-v1
2022-01-26 10:33:58,401 Initializing task ObjectNav-v1
2022-01-26 10:33:58,751 Initializing task ObjectNav-v1
2022-01-26 10:33:58,883 Initializing task ObjectNav-v1
2022-01-26 10:33:58,965 Initializing task ObjectNav-v1
2022-01-26 10:33:58,966 Initializing task ObjectNav-v1
2022-01-26 10:33:59,083 Initializing task ObjectNav-v1
2022-01-26 10:33:59,088 Initializing task ObjectNav-v1
2022-01-26 10:33:59,338 Initializing task ObjectNav-v1
2022-01-26 10:33:59,541 Initializing task ObjectNav-v1
2022-01-26 10:33:59,585 Initializing task ObjectNav-v1
2022-01-26 10:33:59,899 Initializing task ObjectNav-v1
2022-01-26 10:33:59,910 Initializing task ObjectNav-v1
2022-01-26 10:34:00,035 Initializing task ObjectNav-v1
2022-01-26 10:34:00,133 Initializing task ObjectNav-v1
2022-01-26 10:34:00,347 Initializing task ObjectNav-v1
2022-01-26 10:34:00,363 Initializing task ObjectNav-v1
2022-01-26 10:34:00,541 Initializing task ObjectNav-v1
2022-01-26 10:34:00,573 Initializing task ObjectNav-v1
2022-01-26 10:34:00,577 Initializing task ObjectNav-v1
2022-01-26 10:34:00,817 Initializing task ObjectNav-v1
2022-01-26 10:34:00,838 Initializing task ObjectNav-v1
2022-01-26 10:34:01,041 Initializing task ObjectNav-v1
2022-01-26 10:34:01,180 Initializing task ObjectNav-v1
2022-01-26 10:34:01,206 Initializing task ObjectNav-v1
2022-01-26 10:34:01,211 Initializing task ObjectNav-v1
2022-01-26 10:34:01,273 Initializing task ObjectNav-v1
2022-01-26 10:34:01,375 Initializing task ObjectNav-v1
2022-01-26 10:34:01,414 Initializing task ObjectNav-v1
2022-01-26 10:34:01,456 Initializing task ObjectNav-v1
2022-01-26 10:34:01,544 Initializing task ObjectNav-v1
2022-01-26 10:34:01,552 Initializing task ObjectNav-v1
2022-01-26 10:34:01,562 Initializing task ObjectNav-v1
2022-01-26 10:34:01,659 Initializing task ObjectNav-v1
2022-01-26 10:34:01,724 Initializing task ObjectNav-v1
2022-01-26 10:34:01,837 Initializing task ObjectNav-v1
2022-01-26 10:34:01,955 Initializing task ObjectNav-v1
2022-01-26 10:34:01,965 Initializing task ObjectNav-v1
2022-01-26 10:34:02,030 Initializing task ObjectNav-v1
2022-01-26 10:34:02,150 Initializing task ObjectNav-v1
2022-01-26 10:34:02,226 Initializing task ObjectNav-v1
2022-01-26 10:34:02,269 Initializing task ObjectNav-v1
2022-01-26 10:34:02,277 Initializing task ObjectNav-v1
2022-01-26 10:34:02,469 Initializing task ObjectNav-v1
2022-01-26 10:34:02,972 Initializing task ObjectNav-v1
2022-01-26 10:34:03,092 Initializing task ObjectNav-v1
2022-01-26 10:34:03,097 Initializing task ObjectNav-v1
2022-01-26 10:34:03,226 Initializing task ObjectNav-v1
2022-01-26 10:34:03,393 Initializing task ObjectNav-v1
2022-01-26 10:34:03,555 Initializing task ObjectNav-v1
2022-01-26 10:34:03,581 Initializing task ObjectNav-v1
2022-01-26 10:34:03,582 Initializing task ObjectNav-v1
2022-01-26 10:34:03,587 Initializing task ObjectNav-v1
2022-01-26 10:34:03,752 Initializing task ObjectNav-v1
2022-01-26 10:34:03,789 Initializing task ObjectNav-v1
2022-01-26 10:34:03,791 Initializing task ObjectNav-v1
2022-01-26 10:34:03,819 Initializing task ObjectNav-v1
2022-01-26 10:34:03,906 Initializing task ObjectNav-v1
2022-01-26 10:34:04,000 Initializing task ObjectNav-v1
2022-01-26 10:34:04,026 Initializing task ObjectNav-v1
2022-01-26 10:34:04,032 Initializing task ObjectNav-v1
2022-01-26 10:34:04,439 Initializing task ObjectNav-v1
2022-01-26 10:34:04,572 Initializing task ObjectNav-v1
2022-01-26 10:34:04,594 Initializing task ObjectNav-v1
2022-01-26 10:34:04,648 Initializing task ObjectNav-v1
2022-01-26 10:34:04,668 Initializing task ObjectNav-v1
2022-01-26 10:34:04,875 Initializing task ObjectNav-v1
2022-01-26 10:34:04,968 Initializing task ObjectNav-v1
2022-01-26 10:34:05,028 Initializing task ObjectNav-v1
2022-01-26 10:34:05,413 Initializing task ObjectNav-v1
2022-01-26 10:34:05,452 Initializing task ObjectNav-v1
2022-01-26 10:34:05,464 Initializing task ObjectNav-v1
2022-01-26 10:34:05,548 Initializing task ObjectNav-v1
2022-01-26 10:34:05,550 Initializing task ObjectNav-v1
2022-01-26 10:34:05,715 Initializing task ObjectNav-v1
2022-01-26 10:34:05,714 Initializing task ObjectNav-v1
2022-01-26 10:34:05,751 Initializing task ObjectNav-v1
2022-01-26 10:34:05,854 Initializing task ObjectNav-v1
2022-01-26 10:34:05,889 Initializing task ObjectNav-v1
2022-01-26 10:34:05,891 Initializing task ObjectNav-v1
2022-01-26 10:34:05,981 Initializing task ObjectNav-v1
2022-01-26 10:34:06,047 Initializing task ObjectNav-v1
2022-01-26 10:34:06,080 Initializing task ObjectNav-v1
2022-01-26 10:34:06,101 Initializing task ObjectNav-v1
2022-01-26 10:34:06,228 Initializing task ObjectNav-v1
2022-01-26 10:34:06,286 Initializing task ObjectNav-v1
2022-01-26 10:34:06,338 Initializing task ObjectNav-v1
2022-01-26 10:34:06,434 Initializing task ObjectNav-v1
2022-01-26 10:34:06,454 Initializing task ObjectNav-v1
2022-01-26 10:34:06,484 Initializing task ObjectNav-v1
2022-01-26 10:34:06,571 Initializing task ObjectNav-v1
2022-01-26 10:34:06,582 Initializing task ObjectNav-v1
2022-01-26 10:34:06,627 Initializing task ObjectNav-v1
2022-01-26 10:34:06,627 Initializing task ObjectNav-v1
2022-01-26 10:34:06,658 Initializing task ObjectNav-v1
2022-01-26 10:34:06,739 Initializing task ObjectNav-v1
2022-01-26 10:34:06,809 Initializing task ObjectNav-v1
2022-01-26 10:34:06,946 Initializing task ObjectNav-v1
2022-01-26 10:34:06,997 Initializing task ObjectNav-v1
2022-01-26 10:34:07,130 Initializing task ObjectNav-v1
2022-01-26 10:34:07,136 Initializing task ObjectNav-v1
2022-01-26 10:34:07,174 Initializing task ObjectNav-v1
2022-01-26 10:34:07,376 Initializing task ObjectNav-v1
2022-01-26 10:34:07,383 Initializing task ObjectNav-v1
2022-01-26 10:34:07,400 Initializing task ObjectNav-v1
2022-01-26 10:34:07,496 Initializing task ObjectNav-v1
2022-01-26 10:34:07,736 Initializing task ObjectNav-v1
2022-01-26 10:34:07,787 Initializing task ObjectNav-v1
2022-01-26 10:34:07,869 Initializing task ObjectNav-v1
2022-01-26 10:34:07,907 Initializing task ObjectNav-v1
2022-01-26 10:34:07,921 Initializing task ObjectNav-v1
2022-01-26 10:34:08,006 Initializing task ObjectNav-v1
2022-01-26 10:34:08,038 Initializing task ObjectNav-v1
2022-01-26 10:34:08,061 Initializing task ObjectNav-v1
2022-01-26 10:34:08,123 Initializing task ObjectNav-v1
2022-01-26 10:34:08,157 Initializing task ObjectNav-v1
2022-01-26 10:34:08,182 [ train_loader has [5633, 3701, 5553, 5109, 5577, 4539, 4916, 4963] samples ]
2022-01-26 10:34:08,184 obs transforms: []
2022-01-26 10:34:08,220 Initializing task ObjectNav-v1
2022-01-26 10:34:08,232 Initializing task ObjectNav-v1
2022-01-26 10:34:08,519 Not setting up goal seg
2022-01-26 10:34:08,565 Setting up Sem Seg model
2022-01-26 10:34:08,566 

Setting up GPS sensor
2022-01-26 10:34:08,566 

Setting up Compass sensor
2022-01-26 10:34:08,566 

Setting up Object Goal sensor
2022-01-26 10:34:08,578 Initializing task ObjectNav-v1
2022-01-26 10:34:08,848 Initializing task ObjectNav-v1
2022-01-26 10:34:08,913 Initializing task ObjectNav-v1
2022-01-26 10:34:09,231 [ train_loader has [4535, 4559, 4943, 5493, 4342, 5630, 4925, 5564] samples ]
2022-01-26 10:34:09,232 obs transforms: []
2022-01-26 10:34:09,318 Initializing task ObjectNav-v1
2022-01-26 10:34:09,415 Not setting up goal seg
2022-01-26 10:34:09,456 Setting up Sem Seg model
2022-01-26 10:34:09,456 

Setting up GPS sensor
2022-01-26 10:34:09,457 

Setting up Compass sensor
2022-01-26 10:34:09,457 

Setting up Object Goal sensor
2022-01-26 10:34:09,468 Initializing task ObjectNav-v1
2022-01-26 10:34:09,475 Initializing task ObjectNav-v1
2022-01-26 10:34:09,718 Initializing task ObjectNav-v1
2022-01-26 10:34:09,836 Initializing task ObjectNav-v1
2022-01-26 10:34:09,858 Initializing task ObjectNav-v1
2022-01-26 10:34:09,870 Initializing task ObjectNav-v1
2022-01-26 10:34:09,950 Initializing task ObjectNav-v1
2022-01-26 10:34:09,992 Initializing task ObjectNav-v1
2022-01-26 10:34:10,124 Initializing task ObjectNav-v1
2022-01-26 10:34:10,134 Initializing task ObjectNav-v1
2022-01-26 10:34:10,168 [ train_loader has [5055, 5323, 4409, 4977, 5073, 5492, 5418, 4244] samples ]
2022-01-26 10:34:10,170 obs transforms: []
2022-01-26 10:34:10,213 [ train_loader has [5500, 3578, 4936, 4869, 5824, 5409, 4877, 4998] samples ]
2022-01-26 10:34:10,215 obs transforms: []
2022-01-26 10:34:10,226 Initializing task ObjectNav-v1
2022-01-26 10:34:10,358 Not setting up goal seg
2022-01-26 10:34:10,386 initializing sim Sim-v0
2022-01-26 10:34:10,387 Initializing task ObjectNav-v1
2022-01-26 10:34:10,399 Setting up Sem Seg model
2022-01-26 10:34:10,399 

Setting up GPS sensor
2022-01-26 10:34:10,399 

Setting up Compass sensor
2022-01-26 10:34:10,400 

Setting up Object Goal sensor
2022-01-26 10:34:10,400 Not setting up goal seg
2022-01-26 10:34:10,441 Setting up Sem Seg model
2022-01-26 10:34:10,442 

Setting up GPS sensor
2022-01-26 10:34:10,442 

Setting up Compass sensor
2022-01-26 10:34:10,442 

Setting up Object Goal sensor
2022-01-26 10:34:10,492 Initializing task ObjectNav-v1
2022-01-26 10:34:10,514 Initializing task ObjectNav-v1
2022-01-26 10:34:10,536 initializing sim Sim-v0
2022-01-26 10:34:10,578 [ train_loader has [4528, 5600, 5619, 4491, 4068, 5413, 5720, 4552] samples ]
2022-01-26 10:34:10,580 obs transforms: []
2022-01-26 10:34:10,586 Initializing task ObjectNav-v1
2022-01-26 10:34:10,662 Initializing task ObjectNav-v1
2022-01-26 10:34:10,766 Not setting up goal seg
2022-01-26 10:34:10,803 Initializing task ObjectNav-v1
2022-01-26 10:34:10,806 Setting up Sem Seg model
2022-01-26 10:34:10,806 

Setting up GPS sensor
2022-01-26 10:34:10,807 

Setting up Compass sensor
2022-01-26 10:34:10,807 

Setting up Object Goal sensor
2022-01-26 10:34:10,840 Initializing task ObjectNav-v1
2022-01-26 10:34:11,220 Initializing task ObjectNav-v1
2022-01-26 10:34:11,467 Initializing task ObjectNav-v1
2022-01-26 10:34:11,599 Initializing task ObjectNav-v1
2022-01-26 10:34:11,806 initializing sim Sim-v0
2022-01-26 10:34:11,854 Initializing task ObjectNav-v1
2022-01-26 10:34:11,928 [ train_loader has [5258, 4411, 5180, 5166, 4927, 4524, 5070, 5455] samples ]
2022-01-26 10:34:11,930 obs transforms: []
2022-01-26 10:34:11,971 Initializing task ObjectNav-v1
2022-01-26 10:34:11,981 Initializing task ObjectNav-v1
2022-01-26 10:34:12,087 Initializing task ObjectNav-v1
2022-01-26 10:34:12,113 Not setting up goal seg
2022-01-26 10:34:12,153 Setting up Sem Seg model
2022-01-26 10:34:12,153 

Setting up GPS sensor
2022-01-26 10:34:12,153 

Setting up Compass sensor
2022-01-26 10:34:12,154 

Setting up Object Goal sensor
2022-01-26 10:34:12,290 Initializing task ObjectNav-v1
2022-01-26 10:34:12,349 Initializing task ObjectNav-v1
2022-01-26 10:34:12,648 Initializing task ObjectNav-v1
2022-01-26 10:34:12,736 Initializing task ObjectNav-v1
2022-01-26 10:34:12,797 Initializing task ObjectNav-v1
2022-01-26 10:34:12,829 Initializing task ObjectNav-v1
2022-01-26 10:34:12,998 Initializing task ObjectNav-v1
2022-01-26 10:34:13,040 Initializing task ObjectNav-v1
2022-01-26 10:34:13,080 Initializing task ObjectNav-v1
2022-01-26 10:34:13,123 Initializing task ObjectNav-v1
2022-01-26 10:34:13,322 Initializing task ObjectNav-v1
2022-01-26 10:34:13,488 Initializing task ObjectNav-v1
2022-01-26 10:34:13,533 Initializing task ObjectNav-v1
2022-01-26 10:34:13,625 Initializing task ObjectNav-v1
2022-01-26 10:34:13,732 Initializing task ObjectNav-v1
2022-01-26 10:34:13,775 Initializing task ObjectNav-v1
2022-01-26 10:34:13,794 Initializing task ObjectNav-v1
2022-01-26 10:34:13,847 Initializing task ObjectNav-v1
2022-01-26 10:34:13,999 initializing sim Sim-v0
2022-01-26 10:34:14,010 Initializing task ObjectNav-v1
2022-01-26 10:34:14,197 Initializing task ObjectNav-v1
2022-01-26 10:34:14,348 Initializing task ObjectNav-v1
2022-01-26 10:34:14,414 Initializing task ObjectNav-v1
2022-01-26 10:34:14,646 Initializing task ObjectNav-v1
2022-01-26 10:34:14,695 Initializing task ObjectNav-v1
2022-01-26 10:34:15,021 Initializing task ObjectNav-v1
2022-01-26 10:34:15,126 Initializing task ObjectNav-v1
2022-01-26 10:34:15,157 initializing sim Sim-v0
2022-01-26 10:34:15,271 Initializing task ObjectNav-v1
2022-01-26 10:34:15,294 Initializing task ObjectNav-v1
2022-01-26 10:34:15,610 Initializing task ObjectNav-v1
2022-01-26 10:34:15,668 Initializing task ObjectNav-v1
2022-01-26 10:34:15,695 Initializing task ObjectNav-v1
2022-01-26 10:34:15,700 Initializing task ObjectNav-v1
2022-01-26 10:34:15,893 Initializing task ObjectNav-v1
2022-01-26 10:34:15,951 Initializing task ObjectNav-v1
2022-01-26 10:34:15,960 Initializing task ObjectNav-v1
2022-01-26 10:34:16,021 [ train_loader has [4191, 5319, 5532, 4783, 4059, 5484, 5837, 4786] samples ]
2022-01-26 10:34:16,022 obs transforms: []
2022-01-26 10:34:16,210 Not setting up goal seg
2022-01-26 10:34:16,250 Setting up Sem Seg model
2022-01-26 10:34:16,250 

Setting up GPS sensor
2022-01-26 10:34:16,251 

Setting up Compass sensor
2022-01-26 10:34:16,251 

Setting up Object Goal sensor
2022-01-26 10:34:16,270 [ train_loader has [4666, 5486, 5317, 4733, 5735, 4886, 4580, 4588] samples ]
2022-01-26 10:34:16,272 obs transforms: []
2022-01-26 10:34:16,458 Not setting up goal seg
2022-01-26 10:34:16,498 Setting up Sem Seg model
2022-01-26 10:34:16,498 

Setting up GPS sensor
2022-01-26 10:34:16,499 

Setting up Compass sensor
2022-01-26 10:34:16,499 

Setting up Object Goal sensor
2022-01-26 10:34:16,509 Initializing task ObjectNav-v1
2022-01-26 10:34:16,606 Initializing task ObjectNav-v1
2022-01-26 10:34:16,612 Initializing task ObjectNav-v1
2022-01-26 10:34:16,639 Initializing task ObjectNav-v1
2022-01-26 10:34:16,673 initializing sim Sim-v0
2022-01-26 10:34:16,781 Initializing task ObjectNav-v1
2022-01-26 10:34:16,820 Initializing task ObjectNav-v1
2022-01-26 10:34:17,007 Initializing task ObjectNav-v1
2022-01-26 10:34:17,150 Initializing task ObjectNav-v1
2022-01-26 10:34:17,223 Initializing task ObjectNav-v1
2022-01-26 10:34:17,387 [ train_loader has [5382, 5074, 4926, 5510, 4176, 5329, 4723, 4871] samples ]
2022-01-26 10:34:17,389 obs transforms: []
2022-01-26 10:34:17,429 Initializing task ObjectNav-v1
2022-01-26 10:34:17,532 Initializing task ObjectNav-v1
2022-01-26 10:34:17,537 Initializing task ObjectNav-v1
2022-01-26 10:34:17,579 Not setting up goal seg
2022-01-26 10:34:17,620 Setting up Sem Seg model
2022-01-26 10:34:17,620 

Setting up GPS sensor
2022-01-26 10:34:17,620 

Setting up Compass sensor
2022-01-26 10:34:17,621 

Setting up Object Goal sensor
2022-01-26 10:34:17,834 Initializing task ObjectNav-v1
2022-01-26 10:34:17,864 Initializing task ObjectNav-v1
2022-01-26 10:34:17,913 [ train_loader has [5708, 5363, 5071, 5075, 4718, 4529, 5014, 4513] samples ]
2022-01-26 10:34:17,914 obs transforms: []
2022-01-26 10:34:17,998 Initializing task ObjectNav-v1
2022-01-26 10:34:18,058 Initializing task ObjectNav-v1
2022-01-26 10:34:18,098 Not setting up goal seg
2022-01-26 10:34:18,138 Setting up Sem Seg model
2022-01-26 10:34:18,139 

Setting up GPS sensor
2022-01-26 10:34:18,139 

Setting up Compass sensor
2022-01-26 10:34:18,139 

Setting up Object Goal sensor
2022-01-26 10:34:18,433 Initializing task ObjectNav-v1
2022-01-26 10:34:18,453 Initializing task ObjectNav-v1
2022-01-26 10:34:18,659 Initializing task ObjectNav-v1
2022-01-26 10:34:18,684 Initializing task ObjectNav-v1
2022-01-26 10:34:18,702 Initializing task ObjectNav-v1
2022-01-26 10:34:18,795 Initializing task ObjectNav-v1
2022-01-26 10:34:19,051 Initializing task ObjectNav-v1
2022-01-26 10:34:19,110 Initializing task ObjectNav-v1
2022-01-26 10:34:19,305 Initializing task ObjectNav-v1
2022-01-26 10:34:19,323 Initializing task ObjectNav-v1
2022-01-26 10:34:19,653 Initializing task ObjectNav-v1
2022-01-26 10:34:19,663 Initializing task ObjectNav-v1
2022-01-26 10:34:19,741 Initializing task ObjectNav-v1
2022-01-26 10:34:19,766 Initializing task ObjectNav-v1
2022-01-26 10:34:19,814 Initializing task ObjectNav-v1
2022-01-26 10:34:19,852 [ train_loader has [5381, 4106, 5795, 4972, 5686, 4900, 4931, 4220] samples ]
2022-01-26 10:34:19,854 obs transforms: []
2022-01-26 10:34:19,878 Initializing task ObjectNav-v1
2022-01-26 10:34:20,020 [ train_loader has [4809, 5011, 5565, 4824, 4949, 4345, 4970, 5518] samples ]
2022-01-26 10:34:20,024 obs transforms: []
2022-01-26 10:34:20,039 Not setting up goal seg
2022-01-26 10:34:20,080 Setting up Sem Seg model
2022-01-26 10:34:20,080 

Setting up GPS sensor
2022-01-26 10:34:20,080 

Setting up Compass sensor
2022-01-26 10:34:20,081 

Setting up Object Goal sensor
2022-01-26 10:34:20,125 Initializing task ObjectNav-v1
2022-01-26 10:34:20,239 [ train_loader has [5280, 5266, 5448, 5173, 4350, 4971, 5053, 4450] samples ]
2022-01-26 10:34:20,240 obs transforms: []
2022-01-26 10:34:20,407 Not setting up goal seg
2022-01-26 10:34:20,440 Setting up Sem Seg model
2022-01-26 10:34:20,441 

Setting up GPS sensor
2022-01-26 10:34:20,441 

Setting up Compass sensor
2022-01-26 10:34:20,441 

Setting up Object Goal sensor
2022-01-26 10:34:20,564 Initializing task ObjectNav-v1
2022-01-26 10:34:20,579 Initializing task ObjectNav-v1
2022-01-26 10:34:20,600 Not setting up goal seg
2022-01-26 10:34:20,630 Setting up Sem Seg model
2022-01-26 10:34:20,630 

Setting up GPS sensor
2022-01-26 10:34:20,631 

Setting up Compass sensor
2022-01-26 10:34:20,631 

Setting up Object Goal sensor
2022-01-26 10:34:20,643 Initializing task ObjectNav-v1
2022-01-26 10:34:20,645 Initializing task ObjectNav-v1
2022-01-26 10:34:20,701 Initializing task ObjectNav-v1
2022-01-26 10:34:20,733 Initializing task ObjectNav-v1
2022-01-26 10:34:20,743 Initializing task ObjectNav-v1
2022-01-26 10:34:20,784 Initializing task ObjectNav-v1
2022-01-26 10:34:20,823 Initializing task ObjectNav-v1
2022-01-26 10:34:20,930 [ train_loader has [5391, 4964, 5331, 5249, 5542, 3713, 4872, 4929] samples ]
2022-01-26 10:34:20,931 obs transforms: []
2022-01-26 10:34:20,932 Initializing task ObjectNav-v1
2022-01-26 10:34:21,032 [ train_loader has [4815, 4955, 4373, 5129, 5228, 5233, 5326, 4932] samples ]
2022-01-26 10:34:21,034 obs transforms: []
2022-01-26 10:34:21,101 initializing sim Sim-v0
2022-01-26 10:34:21,103 Not setting up goal seg
2022-01-26 10:34:21,140 Setting up Sem Seg model
2022-01-26 10:34:21,140 

Setting up GPS sensor
2022-01-26 10:34:21,141 

Setting up Compass sensor
2022-01-26 10:34:21,141 

Setting up Object Goal sensor
2022-01-26 10:34:21,221 Not setting up goal seg
2022-01-26 10:34:21,262 Setting up Sem Seg model
2022-01-26 10:34:21,262 

Setting up GPS sensor
2022-01-26 10:34:21,262 

Setting up Compass sensor
2022-01-26 10:34:21,263 

Setting up Object Goal sensor
2022-01-26 10:34:21,498 Initializing task ObjectNav-v1
2022-01-26 10:34:21,670 Initializing task ObjectNav-v1
2022-01-26 10:34:21,808 [ train_loader has [5169, 5522, 5224, 4877, 4982, 4410, 5457, 4350] samples ]
2022-01-26 10:34:21,809 obs transforms: []
2022-01-26 10:34:21,851 Initializing task ObjectNav-v1
2022-01-26 10:34:21,970 Initializing task ObjectNav-v1
2022-01-26 10:34:21,991 Not setting up goal seg
2022-01-26 10:34:22,030 Setting up Sem Seg model
2022-01-26 10:34:22,031 

Setting up GPS sensor
2022-01-26 10:34:22,031 

Setting up Compass sensor
2022-01-26 10:34:22,031 

Setting up Object Goal sensor
2022-01-26 10:34:22,043 [ train_loader has [4498, 5285, 5882, 5506, 5311, 4240, 4265, 5004] samples ]
2022-01-26 10:34:22,045 obs transforms: []
2022-01-26 10:34:22,207 Initializing task ObjectNav-v1
2022-01-26 10:34:22,297 Initializing task ObjectNav-v1
2022-01-26 10:34:22,439 Not setting up goal seg
2022-01-26 10:34:22,469 Setting up Sem Seg model
2022-01-26 10:34:22,470 

Setting up GPS sensor
2022-01-26 10:34:22,470 

Setting up Compass sensor
2022-01-26 10:34:22,470 

Setting up Object Goal sensor
2022-01-26 10:34:22,523 [ train_loader has [4606, 5340, 5240, 4167, 5646, 4526, 4776, 5690] samples ]
2022-01-26 10:34:22,525 obs transforms: []
2022-01-26 10:34:22,551 Initializing task ObjectNav-v1
2022-01-26 10:34:22,634 [ train_loader has [5383, 4128, 5162, 4051, 5449, 4903, 5249, 5666] samples ]
2022-01-26 10:34:22,637 obs transforms: []
2022-01-26 10:34:22,648 Initializing task ObjectNav-v1
2022-01-26 10:34:22,700 Not setting up goal seg
2022-01-26 10:34:22,739 Setting up Sem Seg model
2022-01-26 10:34:22,739 

Setting up GPS sensor
2022-01-26 10:34:22,739 

Setting up Compass sensor
2022-01-26 10:34:22,740 

Setting up Object Goal sensor
2022-01-26 10:34:22,766 Initializing task ObjectNav-v1
2022-01-26 10:34:22,790 Initializing task ObjectNav-v1
2022-01-26 10:34:22,812 Not setting up goal seg
2022-01-26 10:34:22,850 Setting up Sem Seg model
2022-01-26 10:34:22,851 

Setting up GPS sensor
2022-01-26 10:34:22,851 

Setting up Compass sensor
2022-01-26 10:34:22,851 

Setting up Object Goal sensor
2022-01-26 10:34:23,291 Initializing task ObjectNav-v1
2022-01-26 10:34:23,447 Initializing task ObjectNav-v1
2022-01-26 10:34:23,494 Initializing task ObjectNav-v1
2022-01-26 10:34:23,747 [ train_loader has [5087, 5005, 4328, 5866, 5037, 4347, 5153, 5168] samples ]
2022-01-26 10:34:23,749 obs transforms: []
2022-01-26 10:34:23,772 Initializing task ObjectNav-v1
2022-01-26 10:34:23,911 Not setting up goal seg
2022-01-26 10:34:23,946 Setting up Sem Seg model
2022-01-26 10:34:23,946 

Setting up GPS sensor
2022-01-26 10:34:23,946 

Setting up Compass sensor
2022-01-26 10:34:23,946 

Setting up Object Goal sensor
2022-01-26 10:34:24,108 Initializing task ObjectNav-v1
2022-01-26 10:34:24,238 Initializing task ObjectNav-v1
2022-01-26 10:34:24,286 Initializing task ObjectNav-v1
2022-01-26 10:34:25,187 Initializing task ObjectNav-v1
2022-01-26 10:34:25,457 [ train_loader has [5090, 4662, 5810, 4635, 4776, 5266, 5199, 4553] samples ]
2022-01-26 10:34:25,460 obs transforms: []
2022-01-26 10:34:25,623 Not setting up goal seg
2022-01-26 10:34:25,661 Setting up Sem Seg model
2022-01-26 10:34:25,661 

Setting up GPS sensor
2022-01-26 10:34:25,661 

Setting up Compass sensor
2022-01-26 10:34:25,662 

Setting up Object Goal sensor
2022-01-26 10:34:25,724 Initializing task ObjectNav-v1
2022-01-26 10:34:25,788 Initializing task ObjectNav-v1
2022-01-26 10:34:26,064 [ train_loader has [4314, 5470, 4728, 5445, 4794, 4683, 4841, 5716] samples ]
2022-01-26 10:34:26,065 obs transforms: []
2022-01-26 10:34:26,189 Initializing task ObjectNav-v1
2022-01-26 10:34:26,232 Not setting up goal seg
2022-01-26 10:34:26,268 Setting up Sem Seg model
2022-01-26 10:34:26,268 

Setting up GPS sensor
2022-01-26 10:34:26,268 

Setting up Compass sensor
2022-01-26 10:34:26,269 

Setting up Object Goal sensor
2022-01-26 10:34:26,268 Initializing task ObjectNav-v1
2022-01-26 10:34:26,421 [ train_loader has [5447, 5546, 4544, 4672, 5686, 5349, 5040, 3707] samples ]
2022-01-26 10:34:26,422 obs transforms: []
2022-01-26 10:34:26,597 Not setting up goal seg
2022-01-26 10:34:26,636 Setting up Sem Seg model
2022-01-26 10:34:26,636 

Setting up GPS sensor
2022-01-26 10:34:26,636 

Setting up Compass sensor
2022-01-26 10:34:26,637 

Setting up Object Goal sensor
2022-01-26 10:34:26,659 Initializing task ObjectNav-v1
2022-01-26 10:34:26,716 Initializing task ObjectNav-v1
2022-01-26 10:34:26,982 [ train_loader has [5859, 5504, 4464, 4958, 5220, 4704, 5046, 4236] samples ]
2022-01-26 10:34:26,983 obs transforms: []
2022-01-26 10:34:27,059 [ train_loader has [4724, 5459, 4874, 4733, 4630, 5028, 5582, 4961] samples ]
2022-01-26 10:34:27,060 obs transforms: []
2022-01-26 10:34:27,162 Not setting up goal seg
2022-01-26 10:34:27,204 Setting up Sem Seg model
2022-01-26 10:34:27,204 

Setting up GPS sensor
2022-01-26 10:34:27,204 

Setting up Compass sensor
2022-01-26 10:34:27,205 

Setting up Object Goal sensor
2022-01-26 10:34:27,227 Not setting up goal seg
2022-01-26 10:34:27,262 Setting up Sem Seg model
2022-01-26 10:34:27,263 

Setting up GPS sensor
2022-01-26 10:34:27,263 

Setting up Compass sensor
2022-01-26 10:34:27,263 

Setting up Object Goal sensor
2022-01-26 10:34:27,602 Initializing task ObjectNav-v1
2022-01-26 10:34:27,968 Initializing task ObjectNav-v1
2022-01-26 10:34:28,325 [ train_loader has [5856, 5070, 5791, 5569, 4183, 3379, 5358, 4785] samples ]
2022-01-26 10:34:28,326 obs transforms: []
2022-01-26 10:34:28,420 Initializing task ObjectNav-v1
2022-01-26 10:34:28,459 Initializing task ObjectNav-v1
2022-01-26 10:34:28,503 Not setting up goal seg
2022-01-26 10:34:28,540 Setting up Sem Seg model
2022-01-26 10:34:28,541 

Setting up GPS sensor
2022-01-26 10:34:28,541 

Setting up Compass sensor
2022-01-26 10:34:28,541 

Setting up Object Goal sensor
2022-01-26 10:34:28,682 [ train_loader has [5347, 4807, 5754, 4221, 5421, 4999, 4812, 4630] samples ]
2022-01-26 10:34:28,684 obs transforms: []
2022-01-26 10:34:28,699 [ train_loader has [5297, 5476, 5697, 5493, 3942, 4855, 4512, 4719] samples ]
2022-01-26 10:34:28,701 obs transforms: []
2022-01-26 10:34:28,704 Initializing task ObjectNav-v1
2022-01-26 10:34:28,875 Not setting up goal seg
2022-01-26 10:34:28,911 Setting up Sem Seg model
2022-01-26 10:34:28,911 

Setting up GPS sensor
2022-01-26 10:34:28,911 

Setting up Compass sensor
2022-01-26 10:34:28,912 

Setting up Object Goal sensor
2022-01-26 10:34:28,992 [ train_loader has [4234, 5372, 4137, 5417, 5559, 5168, 4902, 5202] samples ]
2022-01-26 10:34:28,994 obs transforms: []
2022-01-26 10:34:29,042 Not setting up goal seg
2022-01-26 10:34:29,075 Setting up Sem Seg model
2022-01-26 10:34:29,075 

Setting up GPS sensor
2022-01-26 10:34:29,075 

Setting up Compass sensor
2022-01-26 10:34:29,075 

Setting up Object Goal sensor
2022-01-26 10:34:29,167 Not setting up goal seg
2022-01-26 10:34:29,203 Setting up Sem Seg model
2022-01-26 10:34:29,204 

Setting up GPS sensor
2022-01-26 10:34:29,204 

Setting up Compass sensor
2022-01-26 10:34:29,204 

Setting up Object Goal sensor
2022-01-26 10:34:29,258 Initializing task ObjectNav-v1
2022-01-26 10:34:29,301 Initializing task ObjectNav-v1
2022-01-26 10:34:29,410 Initializing task ObjectNav-v1
2022-01-26 10:34:29,566 Initializing task ObjectNav-v1
2022-01-26 10:34:29,599 [ train_loader has [3958, 4967, 5255, 5081, 5074, 4871, 5535, 5250] samples ]
2022-01-26 10:34:29,601 obs transforms: []
2022-01-26 10:34:29,702 [ train_loader has [5477, 4973, 4255, 5576, 5429, 4650, 4635, 4996] samples ]
2022-01-26 10:34:29,705 obs transforms: []
2022-01-26 10:34:29,772 Not setting up goal seg
2022-01-26 10:34:29,808 Setting up Sem Seg model
2022-01-26 10:34:29,809 

Setting up GPS sensor
2022-01-26 10:34:29,809 

Setting up Compass sensor
2022-01-26 10:34:29,809 

Setting up Object Goal sensor
2022-01-26 10:34:29,877 Not setting up goal seg
2022-01-26 10:34:29,915 Setting up Sem Seg model
2022-01-26 10:34:29,916 

Setting up GPS sensor
2022-01-26 10:34:29,916 

Setting up Compass sensor
2022-01-26 10:34:29,916 

Setting up Object Goal sensor
2022-01-26 10:34:29,926 Initializing task ObjectNav-v1
2022-01-26 10:34:29,943 [ train_loader has [4986, 4743, 5302, 5444, 5157, 4857, 4015, 5487] samples ]
2022-01-26 10:34:29,944 obs transforms: []
2022-01-26 10:34:30,025 Initializing task ObjectNav-v1
2022-01-26 10:34:30,111 Initializing task ObjectNav-v1
2022-01-26 10:34:30,114 Not setting up goal seg
2022-01-26 10:34:30,150 Setting up Sem Seg model
2022-01-26 10:34:30,150 

Setting up GPS sensor
2022-01-26 10:34:30,150 

Setting up Compass sensor
2022-01-26 10:34:30,151 

Setting up Object Goal sensor
2022-01-26 10:34:30,194 [ train_loader has [5234, 4864, 5046, 5348, 3969, 4777, 5198, 5555] samples ]
2022-01-26 10:34:30,195 obs transforms: []
2022-01-26 10:34:30,361 Not setting up goal seg
2022-01-26 10:34:30,396 Setting up Sem Seg model
2022-01-26 10:34:30,397 

Setting up GPS sensor
2022-01-26 10:34:30,397 

Setting up Compass sensor
2022-01-26 10:34:30,397 

Setting up Object Goal sensor
2022-01-26 10:34:30,658 Initializing task ObjectNav-v1
2022-01-26 10:34:31,019 [ train_loader has [5023, 4263, 5776, 4703, 5388, 4872, 5499, 4467] samples ]
2022-01-26 10:34:31,020 obs transforms: []
2022-01-26 10:34:31,025 Initializing task ObjectNav-v1
2022-01-26 10:34:31,051 Initializing task ObjectNav-v1
2022-01-26 10:34:31,103 [ train_loader has [4492, 4797, 5440, 5125, 5207, 5301, 4588, 5041] samples ]
2022-01-26 10:34:31,105 obs transforms: []
2022-01-26 10:34:31,184 Not setting up goal seg
2022-01-26 10:34:31,219 Setting up Sem Seg model
2022-01-26 10:34:31,220 

Setting up GPS sensor
2022-01-26 10:34:31,220 

Setting up Compass sensor
2022-01-26 10:34:31,220 

Setting up Object Goal sensor
2022-01-26 10:34:31,274 Not setting up goal seg
2022-01-26 10:34:31,310 Setting up Sem Seg model
2022-01-26 10:34:31,310 

Setting up GPS sensor
2022-01-26 10:34:31,310 

Setting up Compass sensor
2022-01-26 10:34:31,311 

Setting up Object Goal sensor
2022-01-26 10:34:31,376 [ train_loader has [5390, 5402, 4999, 4737, 5689, 4457, 5185, 4132] samples ]
2022-01-26 10:34:31,378 obs transforms: []
2022-01-26 10:34:31,546 Initializing task ObjectNav-v1
2022-01-26 10:34:31,549 Not setting up goal seg
2022-01-26 10:34:31,584 Setting up Sem Seg model
2022-01-26 10:34:31,584 

Setting up GPS sensor
2022-01-26 10:34:31,584 

Setting up Compass sensor
2022-01-26 10:34:31,584 

Setting up Object Goal sensor
2022-01-26 10:34:31,865 [ train_loader has [3608, 5836, 4191, 4559, 5460, 5522, 5072, 5743] samples ]
2022-01-26 10:34:31,867 obs transforms: []
2022-01-26 10:34:31,985 Initializing task ObjectNav-v1
2022-01-26 10:34:32,002 Initializing task ObjectNav-v1
2022-01-26 10:34:32,032 Not setting up goal seg
2022-01-26 10:34:32,067 Setting up Sem Seg model
2022-01-26 10:34:32,067 

Setting up GPS sensor
2022-01-26 10:34:32,067 

Setting up Compass sensor
2022-01-26 10:34:32,068 

Setting up Object Goal sensor
2022-01-26 10:34:32,305 [ train_loader has [5288, 5137, 5045, 5302, 4378, 4660, 5197, 4984] samples ]
2022-01-26 10:34:32,307 obs transforms: []
2022-01-26 10:34:32,353 [ train_loader has [5367, 4910, 4966, 5187, 4857, 5422, 5399, 3883] samples ]
2022-01-26 10:34:32,358 obs transforms: []
2022-01-26 10:34:32,454 Initializing task ObjectNav-v1
2022-01-26 10:34:32,477 Not setting up goal seg
2022-01-26 10:34:32,511 Setting up Sem Seg model
2022-01-26 10:34:32,512 

Setting up GPS sensor
2022-01-26 10:34:32,512 

Setting up Compass sensor
2022-01-26 10:34:32,512 

Setting up Object Goal sensor
2022-01-26 10:34:32,522 Not setting up goal seg
2022-01-26 10:34:32,558 Setting up Sem Seg model
2022-01-26 10:34:32,558 

Setting up GPS sensor
2022-01-26 10:34:32,559 

Setting up Compass sensor
2022-01-26 10:34:32,559 

Setting up Object Goal sensor
2022-01-26 10:34:32,779 [ train_loader has [4984, 4140, 5303, 5418, 4935, 5549, 5005, 4657] samples ]
2022-01-26 10:34:32,781 obs transforms: []
2022-01-26 10:34:32,949 Not setting up goal seg
2022-01-26 10:34:32,985 Setting up Sem Seg model
2022-01-26 10:34:32,985 

Setting up GPS sensor
2022-01-26 10:34:32,985 

Setting up Compass sensor
2022-01-26 10:34:32,985 

Setting up Object Goal sensor
2022-01-26 10:34:33,142 Initializing task ObjectNav-v1
2022-01-26 10:34:34,009 Initializing task ObjectNav-v1
2022-01-26 10:34:34,304 Initializing task ObjectNav-v1
2022-01-26 10:34:34,312 [ train_loader has [4988, 4418, 5369, 4621, 4927, 5771, 5325, 4572] samples ]
2022-01-26 10:34:34,318 obs transforms: []
2022-01-26 10:34:34,480 Not setting up goal seg
2022-01-26 10:34:34,514 Initializing task ObjectNav-v1
2022-01-26 10:34:34,517 Setting up Sem Seg model
2022-01-26 10:34:34,517 

Setting up GPS sensor
2022-01-26 10:34:34,517 

Setting up Compass sensor
2022-01-26 10:34:34,517 

Setting up Object Goal sensor
2022-01-26 10:34:34,684 Initializing task ObjectNav-v1
2022-01-26 10:34:34,764 [ train_loader has [4384, 4898, 5361, 4455, 4672, 5114, 5369, 5738] samples ]
2022-01-26 10:34:34,767 obs transforms: []
2022-01-26 10:34:34,774 Initializing task ObjectNav-v1
2022-01-26 10:34:34,955 [ train_loader has [5285, 5363, 5147, 5284, 4800, 4444, 4254, 5414] samples ]
2022-01-26 10:34:34,957 obs transforms: []
2022-01-26 10:34:35,122 Not setting up goal seg
2022-01-26 10:34:35,131 Not setting up goal seg
2022-01-26 10:34:35,158 Setting up Sem Seg model
2022-01-26 10:34:35,158 

Setting up GPS sensor
2022-01-26 10:34:35,158 

Setting up Compass sensor
2022-01-26 10:34:35,158 

Setting up Object Goal sensor
2022-01-26 10:34:35,160 Setting up Sem Seg model
2022-01-26 10:34:35,160 

Setting up GPS sensor
2022-01-26 10:34:35,160 

Setting up Compass sensor
2022-01-26 10:34:35,160 

Setting up Object Goal sensor
2022-01-26 10:34:35,361 Initializing task ObjectNav-v1
2022-01-26 10:34:35,606 [ train_loader has [4021, 5739, 4778, 5264, 4707, 5628, 4720, 5134] samples ]
2022-01-26 10:34:35,607 obs transforms: []
2022-01-26 10:34:35,780 Not setting up goal seg
2022-01-26 10:34:35,817 Setting up Sem Seg model
2022-01-26 10:34:35,818 

Setting up GPS sensor
2022-01-26 10:34:35,818 

Setting up Compass sensor
2022-01-26 10:34:35,818 

Setting up Object Goal sensor
2022-01-26 10:34:36,091 Initializing task ObjectNav-v1
2022-01-26 10:34:36,404 Initializing task ObjectNav-v1
2022-01-26 10:34:36,450 [ train_loader has [5292, 5122, 4496, 5081, 4697, 5410, 5015, 4878] samples ]
2022-01-26 10:34:36,452 obs transforms: []
2022-01-26 10:34:36,616 Not setting up goal seg
2022-01-26 10:34:36,651 Setting up Sem Seg model
2022-01-26 10:34:36,651 

Setting up GPS sensor
2022-01-26 10:34:36,651 

Setting up Compass sensor
2022-01-26 10:34:36,651 

Setting up Object Goal sensor
2022-01-26 10:34:37,154 Initializing task ObjectNav-v1
2022-01-26 10:34:37,249 initializing sim Sim-v0
2022-01-26 10:34:37,489 [ train_loader has [5960, 5431, 4593, 4844, 4280, 4588, 4922, 5373] samples ]
2022-01-26 10:34:37,492 obs transforms: []
2022-01-26 10:34:37,546 Initializing task ObjectNav-v1
2022-01-26 10:34:37,567 Initializing task ObjectNav-v1
2022-01-26 10:34:37,656 Not setting up goal seg
2022-01-26 10:34:37,691 Setting up Sem Seg model
2022-01-26 10:34:37,691 

Setting up GPS sensor
2022-01-26 10:34:37,692 

Setting up Compass sensor
2022-01-26 10:34:37,692 

Setting up Object Goal sensor
2022-01-26 10:34:37,963 Initializing task ObjectNav-v1
2022-01-26 10:34:38,394 Initializing task ObjectNav-v1
2022-01-26 10:34:38,454 [ train_loader has [4661, 4988, 4089, 5298, 5502, 4924, 4739, 5790] samples ]
2022-01-26 10:34:38,456 obs transforms: []
2022-01-26 10:34:38,604 Not setting up goal seg
2022-01-26 10:34:38,634 Setting up Sem Seg model
2022-01-26 10:34:38,634 

Setting up GPS sensor
2022-01-26 10:34:38,634 

Setting up Compass sensor
2022-01-26 10:34:38,634 

Setting up Object Goal sensor
2022-01-26 10:34:38,690 [ train_loader has [5354, 5103, 5637, 5154, 3976, 5479, 4572, 4716] samples ]
2022-01-26 10:34:38,691 obs transforms: []
2022-01-26 10:34:38,811 Initializing task ObjectNav-v1
2022-01-26 10:34:38,877 Not setting up goal seg
2022-01-26 10:34:38,916 Setting up Sem Seg model
2022-01-26 10:34:38,916 

Setting up GPS sensor
2022-01-26 10:34:38,917 

Setting up Compass sensor
2022-01-26 10:34:38,917 

Setting up Object Goal sensor
2022-01-26 10:34:40,326 Initializing task ObjectNav-v1
2022-01-26 10:34:40,550 [ train_loader has [5764, 3790, 4538, 5818, 4485, 5234, 5163, 5199] samples ]
2022-01-26 10:34:40,552 obs transforms: []
2022-01-26 10:34:40,724 Not setting up goal seg
2022-01-26 10:34:40,761 Setting up Sem Seg model
2022-01-26 10:34:40,761 

Setting up GPS sensor
2022-01-26 10:34:40,761 

Setting up Compass sensor
2022-01-26 10:34:40,762 

Setting up Object Goal sensor
2022-01-26 10:34:40,832 Initializing task ObjectNav-v1
2022-01-26 10:34:41,166 Initializing task ObjectNav-v1
2022-01-26 10:34:41,291 Initializing task ObjectNav-v1
2022-01-26 10:34:41,335 Initializing task ObjectNav-v1
2022-01-26 10:34:41,396 [ train_loader has [5469, 5120, 4725, 4779, 5355, 4817, 5125, 4601] samples ]
2022-01-26 10:34:41,397 obs transforms: []
2022-01-26 10:34:41,541 Not setting up goal seg
2022-01-26 10:34:41,577 Setting up Sem Seg model
2022-01-26 10:34:41,577 

Setting up GPS sensor
2022-01-26 10:34:41,577 

Setting up Compass sensor
2022-01-26 10:34:41,577 

Setting up Object Goal sensor
2022-01-26 10:34:41,579 [ train_loader has [5443, 4170, 5521, 4576, 4613, 5170, 4839, 5659] samples ]
2022-01-26 10:34:41,582 obs transforms: []
2022-01-26 10:34:41,625 [ train_loader has [4666, 5419, 4682, 4695, 5485, 5463, 4542, 5039] samples ]
2022-01-26 10:34:41,627 obs transforms: []
2022-01-26 10:34:41,750 Not setting up goal seg
2022-01-26 10:34:41,787 Setting up Sem Seg model
2022-01-26 10:34:41,787 

Setting up GPS sensor
2022-01-26 10:34:41,787 

Setting up Compass sensor
2022-01-26 10:34:41,788 

Setting up Object Goal sensor
2022-01-26 10:34:41,796 Not setting up goal seg
2022-01-26 10:34:41,833 Setting up Sem Seg model
2022-01-26 10:34:41,833 

Setting up GPS sensor
2022-01-26 10:34:41,834 

Setting up Compass sensor
2022-01-26 10:34:41,834 

Setting up Object Goal sensor
2022-01-26 10:34:44,780 Initializing task ObjectNav-v1
2022-01-26 10:34:44,898 Initializing task ObjectNav-v1
2022-01-26 10:34:45,489 Initializing task ObjectNav-v1
2022-01-26 10:34:49,445 Initializing task ObjectNav-v1
2022-01-26 10:34:49,457 Initializing task ObjectNav-v1
2022-01-26 10:34:49,727 [ train_loader has [5092, 5402, 5678, 4894, 5075, 5366, 3966, 4518] samples ]
2022-01-26 10:34:49,729 obs transforms: []
2022-01-26 10:34:49,776 [ train_loader has [4619, 3597, 5138, 5573, 4850, 5926, 5501, 4787] samples ]
2022-01-26 10:34:49,778 obs transforms: []
2022-01-26 10:34:49,892 Not setting up goal seg
2022-01-26 10:34:49,930 Setting up Sem Seg model
2022-01-26 10:34:49,931 

Setting up GPS sensor
2022-01-26 10:34:49,931 

Setting up Compass sensor
2022-01-26 10:34:49,931 

Setting up Object Goal sensor
2022-01-26 10:34:49,985 Not setting up goal seg
2022-01-26 10:34:50,022 Setting up Sem Seg model
2022-01-26 10:34:50,022 

Setting up GPS sensor
2022-01-26 10:34:50,023 

Setting up Compass sensor
2022-01-26 10:34:50,023 

Setting up Object Goal sensor
2022-01-26 10:34:52,028 Initializing task ObjectNav-v1
2022-01-26 10:34:52,278 [ train_loader has [5649, 4750, 5240, 5088, 5640, 5260, 4927, 3437] samples ]
2022-01-26 10:34:52,279 obs transforms: []
2022-01-26 10:34:52,421 Not setting up goal seg
2022-01-26 10:34:52,450 Setting up Sem Seg model
2022-01-26 10:34:52,451 

Setting up GPS sensor
2022-01-26 10:34:52,451 

Setting up Compass sensor
2022-01-26 10:34:52,451 

Setting up Object Goal sensor
2022-01-26 10:34:56,698 Initializing task ObjectNav-v1
2022-01-26 10:34:57,484 [ train_loader has [5182, 5601, 3909, 4963, 4816, 5389, 4576, 5555] samples ]
2022-01-26 10:34:57,486 obs transforms: []
2022-01-26 10:34:57,679 Not setting up goal seg
2022-01-26 10:34:57,708 Setting up Sem Seg model
2022-01-26 10:34:57,708 

Setting up GPS sensor
2022-01-26 10:34:57,708 

Setting up Compass sensor
2022-01-26 10:34:57,708 

Setting up Object Goal sensor
2022-01-26 10:34:59,139 agent number of trainable parameters: 50012622
Process ForkServerProcess-1:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'kitchenware'
Process ForkServerProcess-7:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'kitchenware'
Process ForkServerProcess-5:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'plaything'
Process ForkServerProcess-8:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'plaything'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Process ForkServerProcess-8:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'stationery'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Process ForkServerProcess-8:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'foodstuff'
Process ForkServerProcess-1:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'kitchenware'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
Process ForkServerProcess-7:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'hand_tool'
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-1:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'hand_tool'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Process ForkServerProcess-6:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'fruit'
Process ForkServerProcess-1:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'hand_tool'
Process ForkServerProcess-2:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'fruit'
Process ForkServerProcess-3:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'foodstuff'
Process ForkServerProcess-8:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'plaything'
Process ForkServerProcess-7:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'stationery'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
Process ForkServerProcess-7:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'fruit'
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
Process ForkServerProcess-6:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'game_equipment'
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Process ForkServerProcess-3:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'hand_tool'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-2:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'kitchenware'
Process ForkServerProcess-1:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'kitchenware'
Process ForkServerProcess-6:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'fruit'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Process ForkServerProcess-4:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'kitchenware'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Process ForkServerProcess-5:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'stationery'
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    observations = self.envs.reset()
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Process ForkServerProcess-7:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'fruit'
Process ForkServerProcess-7:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'hand_tool'
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-3:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'game_equipment'
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-1:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'plaything'
Process ForkServerProcess-4:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'game_equipment'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-1:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'foodstuff'
Process ForkServerProcess-5:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'hand_tool'
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-8:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'plaything'
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-7:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'kitchenware'
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-7:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'game_equipment'
Process ForkServerProcess-1:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'stationery'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-8:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'stationery'
Process ForkServerProcess-2:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'fruit'
Process ForkServerProcess-5:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'foodstuff'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Process ForkServerProcess-6:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'stationery'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-2:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'game_equipment'
Process ForkServerProcess-7:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'game_equipment'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Process ForkServerProcess-4:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'stationery'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Process ForkServerProcess-6:
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 225, in _worker_env
    observations = env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/common/environments.py", line 47, in reset
    observations = super().reset()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 405, in reset
    return self._env.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/env.py", line 224, in reset
    observations = self.task.reset(episode=self.current_episode)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/embodied_task.py", line 286, in reset
    observations=observations, episode=episode, task=self
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 214, in get_observations
    return Observations(self.sensors, *args, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in __init__
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/simulator.py", line 110, in <listcomp>
    for uuid, sensor in sensors.items()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/tasks/nav/object_nav_task.py", line 255, in get_observation
    [self._dataset.category_to_task_category_id[category_name]],
KeyError: 'kitchenware'
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 206, in train
    observations = self.envs.reset()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/core/vector_env.py", line 427, in reset
    results.append(read_fn())
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
slurmstepd: error: *** STEP 52465258.1 ON learnfair1174 CANCELLED AT 2022-01-26T10:38:52 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 52465258 ON learnfair1174 CANCELLED AT 2022-01-26T10:38:52 ***
