/bin/bash: /public/apps/anaconda3/2020.11/lib/libtinfo.so.6: no version information available (required by /bin/bash)
+ [[ env == \e\n\v ]]
+ echo 'In ObjectNav Env DDP'
+ srun /private/home/abhshkdz/.conda/envs/habitat-on-web/bin/python -u -m habitat_baselines.run --exp-config habitat_baselines/config/objectnav/il_ddp_env_objectnav.yaml --run-type train
2021-06-14 15:45:54,827 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_v4/seed_1
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v4/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: sample
  USE_CKPT_CONFIG: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/overfitting/seed_3/ckpt.3.pth
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v4/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    hidden_size: 512
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 1
    num_steps: 128
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_tuned.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 512
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 7000
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_sge: True
  force_blind_policy: False
  hidden_size: 512
  inflection_weight_coef: 3.4761714413101563
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 7
NUM_UPDATES: 9000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v4/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v4/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
2021-06-14 15:45:54,828 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_v4/seed_1
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v4/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: sample
  USE_CKPT_CONFIG: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/overfitting/seed_3/ckpt.3.pth
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v4/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    hidden_size: 512
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 1
    num_steps: 128
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_tuned.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 512
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 7000
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_sge: True
  force_blind_policy: False
  hidden_size: 512
  inflection_weight_coef: 3.4761714413101563
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 7
NUM_UPDATES: 9000
ORBSLAM2:
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v4/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v4/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_v4/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5456
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_v4/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5456
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.4761714413101563
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    POINTGOAL_SENSOR:
2021-06-14 15:45:54,828 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_v4/seed_1
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v4/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: sample
  USE_CKPT_CONFIG: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/overfitting/seed_3/ckpt.3.pth
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v4/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    hidden_size: 512
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 1
    num_steps: 128
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      DIMENSIONALITY: 2
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_tuned.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 512
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 7000
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_sge: True
  force_blind_policy: False
  hidden_size: 512
  inflection_weight_coef: 3.4761714413101563
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 7
NUM_UPDATES: 9000
ORBSLAM2:
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'INFLECTION_WEIGHT_SENSOR', 'DEMONSTRATION_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 2048
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v4/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v4/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.4761714413101563
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    POINTGOAL_SENSOR:
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_v4/seed_1/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_v4/seed_1/
VIDEO_OPTION: ['disk']
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      DIMENSIONALITY: 2
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'INFLECTION_WEIGHT_SENSOR', 'DEMONSTRATION_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 2048
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_v4/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5456
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_v4/seed_1/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_v4/seed_1/
VIDEO_OPTION: ['disk']
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.4761714413101563
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'INFLECTION_WEIGHT_SENSOR', 'DEMONSTRATION_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 2048
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_v4/seed_1/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_v4/seed_1/
VIDEO_OPTION: ['disk']
2021-06-14 15:45:54,831 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_v4/seed_1
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v4/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: sample
  USE_CKPT_CONFIG: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/overfitting/seed_3/ckpt.3.pth
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v4/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    hidden_size: 512
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 1
    num_steps: 128
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
2021-06-14 15:45:54,831 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_v4/seed_1
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v4/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: sample
  USE_CKPT_CONFIG: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/overfitting/seed_3/ckpt.3.pth
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v4/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    hidden_size: 512
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 1
    num_steps: 128
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_tuned.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 512
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 7000
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_sge: True
  force_blind_policy: False
  hidden_size: 512
  inflection_weight_coef: 3.4761714413101563
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 7
NUM_UPDATES: 9000
ORBSLAM2:
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_tuned.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 512
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 7000
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_sge: True
  force_blind_policy: False
  hidden_size: 512
  inflection_weight_coef: 3.4761714413101563
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 7
NUM_UPDATES: 9000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v4/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v4/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v4/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v4/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_v4/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5456
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_v4/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5456
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.4761714413101563
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    POINTGOAL_SENSOR:
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.4761714413101563
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'INFLECTION_WEIGHT_SENSOR', 'DEMONSTRATION_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 2048
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'INFLECTION_WEIGHT_SENSOR', 'DEMONSTRATION_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 2048
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_v4/seed_1/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_v4/seed_1/
VIDEO_OPTION: ['disk']
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_v4/seed_1/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_v4/seed_1/
VIDEO_OPTION: ['disk']
2021-06-14 15:45:54,834 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_v4/seed_1
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v4/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: sample
  USE_CKPT_CONFIG: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/overfitting/seed_3/ckpt.3.pth
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v4/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    hidden_size: 512
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 1
    num_steps: 128
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_tuned.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 512
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 7000
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_sge: True
  force_blind_policy: False
  hidden_size: 512
  inflection_weight_coef: 3.4761714413101563
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 7
NUM_UPDATES: 9000
ORBSLAM2:
2021-06-14 15:45:54,834 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_v4/seed_1
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v4/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: sample
  USE_CKPT_CONFIG: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/overfitting/seed_3/ckpt.3.pth
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v4/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    hidden_size: 512
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 1
    num_steps: 128
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v4/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v4/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_tuned.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 512
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 7000
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_sge: True
  force_blind_policy: False
  hidden_size: 512
  inflection_weight_coef: 3.4761714413101563
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 7
NUM_UPDATES: 9000
ORBSLAM2:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v4/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v4/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_v4/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5456
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_v4/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5456
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.4761714413101563
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    POINTGOAL_SENSOR:
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
      DIMENSIONALITY: 2
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.4761714413101563
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    POINTGOAL_SENSOR:
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'INFLECTION_WEIGHT_SENSOR', 'DEMONSTRATION_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 2048
      DIMENSIONALITY: 2
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_v4/seed_1/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_v4/seed_1/
VIDEO_OPTION: ['disk']
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'INFLECTION_WEIGHT_SENSOR', 'DEMONSTRATION_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 2048
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_v4/seed_1/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_v4/seed_1/
VIDEO_OPTION: ['disk']
2021-06-14 15:45:54,837 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_v4/seed_1
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v4/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: sample
  USE_CKPT_CONFIG: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/overfitting/seed_3/ckpt.3.pth
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v4/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    hidden_size: 512
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 1
    num_steps: 128
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_tuned.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 512
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 7000
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_sge: True
  force_blind_policy: False
  hidden_size: 512
  inflection_weight_coef: 3.4761714413101563
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 7
NUM_UPDATES: 9000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v4/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v4/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_v4/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5456
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'SEMANTIC_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.4761714413101563
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'INFLECTION_WEIGHT_SENSOR', 'DEMONSTRATION_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 2048
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_v4/seed_1/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_v4/seed_1/
VIDEO_OPTION: ['disk']
2021-06-14 15:45:55,374 Initializing dataset ObjectNav-v2
2021-06-14 15:45:55,376 Initializing dataset ObjectNav-v2
2021-06-14 15:45:55,378 Initializing dataset ObjectNav-v2
2021-06-14 15:45:55,378 Initializing dataset ObjectNav-v2
2021-06-14 15:45:55,389 Initializing dataset ObjectNav-v2
2021-06-14 15:45:55,393 Initializing dataset ObjectNav-v2
2021-06-14 15:45:55,400 Initializing dataset ObjectNav-v2
2021-06-14 15:45:55,420 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,780 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,780 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,781 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,781 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,781 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,798 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,819 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,820 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,820 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,821 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,821 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,828 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,833 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,834 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,834 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,834 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,837 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,840 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,841 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,895 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,895 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,897 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,897 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,897 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,898 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,898 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,898 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,898 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,898 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,899 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,904 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,919 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,919 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,919 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,919 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,921 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,921 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,930 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,932 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,932 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,932 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,933 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,943 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,951 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,955 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,967 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,976 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,982 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,983 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,983 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,984 Initializing dataset ObjectNav-v2
2021-06-14 15:45:59,984 Initializing dataset ObjectNav-v2
2021-06-14 15:46:00,019 Initializing dataset ObjectNav-v2
2021-06-14 15:46:00,035 Initializing dataset ObjectNav-v2
2021-06-14 15:46:00,095 Initializing dataset ObjectNav-v2
2021-06-14 15:46:00,173 Initializing dataset ObjectNav-v2
2021-06-14 15:46:16,706 initializing sim Sim-v0
2021-06-14 15:46:16,883 initializing sim Sim-v0
2021-06-14 15:46:17,891 initializing sim Sim-v0
2021-06-14 15:46:18,800 initializing sim Sim-v0
2021-06-14 15:46:19,126 initializing sim Sim-v0
2021-06-14 15:46:19,190 initializing sim Sim-v0
2021-06-14 15:46:19,404 initializing sim Sim-v0
2021-06-14 15:46:19,452 initializing sim Sim-v0
2021-06-14 15:46:19,482 initializing sim Sim-v0
2021-06-14 15:46:19,892 initializing sim Sim-v0
2021-06-14 15:46:20,444 initializing sim Sim-v0
2021-06-14 15:46:20,614 initializing sim Sim-v0
2021-06-14 15:46:20,728 initializing sim Sim-v0
2021-06-14 15:46:20,802 initializing sim Sim-v0
2021-06-14 15:46:21,056 initializing sim Sim-v0
2021-06-14 15:46:21,102 initializing sim Sim-v0
2021-06-14 15:46:21,333 initializing sim Sim-v0
2021-06-14 15:46:22,170 initializing sim Sim-v0
2021-06-14 15:46:22,174 initializing sim Sim-v0
2021-06-14 15:46:22,317 initializing sim Sim-v0
2021-06-14 15:46:22,440 initializing sim Sim-v0
2021-06-14 15:46:22,517 initializing sim Sim-v0
2021-06-14 15:46:22,667 initializing sim Sim-v0
2021-06-14 15:46:22,896 initializing sim Sim-v0
2021-06-14 15:46:23,449 initializing sim Sim-v0
2021-06-14 15:46:23,475 initializing sim Sim-v0
2021-06-14 15:46:23,892 initializing sim Sim-v0
2021-06-14 15:46:23,984 Initializing task ObjectNav-v1
2021-06-14 15:46:24,000 initializing sim Sim-v0
2021-06-14 15:46:24,019 initializing sim Sim-v0
2021-06-14 15:46:24,125 initializing sim Sim-v0
2021-06-14 15:46:24,688 initializing sim Sim-v0
2021-06-14 15:46:24,778 initializing sim Sim-v0
2021-06-14 15:46:24,817 initializing sim Sim-v0
2021-06-14 15:46:24,927 initializing sim Sim-v0
2021-06-14 15:46:25,132 initializing sim Sim-v0
2021-06-14 15:46:25,231 initializing sim Sim-v0
2021-06-14 15:46:25,263 initializing sim Sim-v0
2021-06-14 15:46:25,276 initializing sim Sim-v0
2021-06-14 15:46:25,616 initializing sim Sim-v0
2021-06-14 15:46:25,772 initializing sim Sim-v0
2021-06-14 15:46:26,039 Initializing task ObjectNav-v1
2021-06-14 15:46:26,327 initializing sim Sim-v0
2021-06-14 15:46:26,402 initializing sim Sim-v0
2021-06-14 15:46:26,461 Initializing task ObjectNav-v1
2021-06-14 15:46:26,731 initializing sim Sim-v0
2021-06-14 15:46:26,821 initializing sim Sim-v0
2021-06-14 15:46:27,524 initializing sim Sim-v0
2021-06-14 15:46:27,849 initializing sim Sim-v0
2021-06-14 15:46:27,975 Initializing task ObjectNav-v1
2021-06-14 15:46:28,037 initializing sim Sim-v0
2021-06-14 15:46:28,069 initializing sim Sim-v0
2021-06-14 15:46:28,228 initializing sim Sim-v0
2021-06-14 15:46:28,236 initializing sim Sim-v0
2021-06-14 15:46:28,239 initializing sim Sim-v0
2021-06-14 15:46:28,491 initializing sim Sim-v0
2021-06-14 15:46:28,845 initializing sim Sim-v0
2021-06-14 15:46:28,873 Initializing task ObjectNav-v1
2021-06-14 15:46:28,986 initializing sim Sim-v0
2021-06-14 15:46:29,787 initializing sim Sim-v0
2021-06-14 15:46:30,185 initializing sim Sim-v0
2021-06-14 15:46:32,714 Initializing task ObjectNav-v1
2021-06-14 15:46:34,511 Initializing task ObjectNav-v1
2021-06-14 15:46:35,022 Initializing task ObjectNav-v1
2021-06-14 15:46:36,024 Initializing task ObjectNav-v1
2021-06-14 15:46:36,263 Initializing task ObjectNav-v1
2021-06-14 15:46:36,500 Initializing task ObjectNav-v1
2021-06-14 15:46:36,744 Initializing task ObjectNav-v1
2021-06-14 15:46:36,961 Initializing task ObjectNav-v1
2021-06-14 15:46:37,288 Initializing task ObjectNav-v1
2021-06-14 15:46:37,403 Initializing task ObjectNav-v1
2021-06-14 15:46:37,461 Initializing task ObjectNav-v1
2021-06-14 15:46:37,745 Initializing task ObjectNav-v1
2021-06-14 15:46:38,456 Initializing task ObjectNav-v1
2021-06-14 15:46:38,595 Initializing task ObjectNav-v1
2021-06-14 15:46:38,746 Initializing task ObjectNav-v1
2021-06-14 15:46:40,061 Initializing task ObjectNav-v1
2021-06-14 15:46:40,077 Initializing task ObjectNav-v1
2021-06-14 15:46:40,271 Initializing task ObjectNav-v1
2021-06-14 15:46:40,310 Initializing task ObjectNav-v1
2021-06-14 15:46:40,587 Initializing task ObjectNav-v1
2021-06-14 15:46:41,265 Initializing task ObjectNav-v1
2021-06-14 15:46:41,306 Initializing task ObjectNav-v1
2021-06-14 15:46:41,778 Initializing task ObjectNav-v1
2021-06-14 15:46:41,965 Initializing task ObjectNav-v1
2021-06-14 15:46:42,125 Initializing task ObjectNav-v1
2021-06-14 15:46:42,166 Initializing task ObjectNav-v1
2021-06-14 15:46:42,860 Initializing task ObjectNav-v1
2021-06-14 15:46:43,247 Initializing task ObjectNav-v1
2021-06-14 15:46:43,304 Initializing task ObjectNav-v1
2021-06-14 15:46:44,433 Initializing task ObjectNav-v1
2021-06-14 15:46:44,972 Initializing task ObjectNav-v1
2021-06-14 15:46:45,099 Initializing task ObjectNav-v1
2021-06-14 15:46:45,800 Initializing task ObjectNav-v1
2021-06-14 15:46:46,573 Initializing task ObjectNav-v1
2021-06-14 15:46:46,758 Initializing task ObjectNav-v1
2021-06-14 15:46:46,990 Initializing task ObjectNav-v1
2021-06-14 15:46:47,139 Initializing task ObjectNav-v1
2021-06-14 15:46:47,204 [ train_loader has [1885, 1643, 1802, 1494, 1980, 2081, 1929] samples ]
2021-06-14 15:46:47,591 Setting up Sem Seg model
2021-06-14 15:46:47,591 

Setting up GPS sensor
2021-06-14 15:46:47,592 

Setting up Compass sensor
2021-06-14 15:46:47,592 

Setting up Object Goal sensor
2021-06-14 15:46:48,990 Initializing task ObjectNav-v1
2021-06-14 15:46:49,626 Initializing task ObjectNav-v1
2021-06-14 15:46:50,047 [ train_loader has [2010, 1710, 1813, 1620, 1884, 1871, 1906] samples ]
2021-06-14 15:46:50,230 Initializing task ObjectNav-v1
2021-06-14 15:46:50,356 Setting up Sem Seg model
2021-06-14 15:46:50,356 

Setting up GPS sensor
2021-06-14 15:46:50,356 

Setting up Compass sensor
2021-06-14 15:46:50,357 

Setting up Object Goal sensor
2021-06-14 15:46:50,501 [ train_loader has [1766, 1832, 1943, 1795, 2042, 2082, 1354] samples ]
2021-06-14 15:46:50,828 Setting up Sem Seg model
2021-06-14 15:46:50,828 

Setting up GPS sensor
2021-06-14 15:46:50,828 

Setting up Compass sensor
2021-06-14 15:46:50,828 

Setting up Object Goal sensor
2021-06-14 15:46:52,998 Initializing task ObjectNav-v1
2021-06-14 15:46:53,453 Initializing task ObjectNav-v1
2021-06-14 15:46:53,536 Initializing task ObjectNav-v1
2021-06-14 15:46:53,907 Initializing task ObjectNav-v1
2021-06-14 15:46:54,147 Initializing task ObjectNav-v1
2021-06-14 15:46:56,371 Initializing task ObjectNav-v1
2021-06-14 15:46:56,659 [ train_loader has [1828, 2121, 2065, 1219, 1855, 1806, 1920] samples ]
2021-06-14 15:46:56,986 Setting up Sem Seg model
2021-06-14 15:46:56,987 

Setting up GPS sensor
2021-06-14 15:46:56,987 

Setting up Compass sensor
2021-06-14 15:46:56,987 

Setting up Object Goal sensor
2021-06-14 15:46:56,990 Initializing task ObjectNav-v1
2021-06-14 15:46:57,092 Initializing task ObjectNav-v1
2021-06-14 15:46:57,279 [ train_loader has [1837, 1519, 1788, 1883, 1824, 1870, 2093] samples ]
2021-06-14 15:46:57,306 [ train_loader has [1758, 1670, 1764, 2163, 2075, 1511, 1873] samples ]
2021-06-14 15:46:57,591 Setting up Sem Seg model
2021-06-14 15:46:57,592 

Setting up GPS sensor
2021-06-14 15:46:57,592 

Setting up Compass sensor
2021-06-14 15:46:57,592 

Setting up Object Goal sensor
2021-06-14 15:46:57,612 Setting up Sem Seg model
2021-06-14 15:46:57,613 

Setting up GPS sensor
2021-06-14 15:46:57,613 

Setting up Compass sensor
2021-06-14 15:46:57,613 

Setting up Object Goal sensor
2021-06-14 15:47:02,792 Initializing task ObjectNav-v1
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
2021-06-14 15:47:16,819 Initializing task ObjectNav-v1
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 342, in train
    ) = self._update_agent(il_cfg, rollouts)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_trainer.py", line 267, in _update_agent
    total_loss, rnn_hidden_states = self.agent.update(rollouts)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/agent.py", line 75, in update
    masks_batch,
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 337, in forward
    observations, rnn_hidden_states, prev_actions, masks
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 275, in forward
    sem_seg_embedding = self.sem_seg_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rearrangement/models/encoders/resnet_encoders.py", line 395, in forward
    x = self.visual_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet_policy.py", line 218, in forward
    x = self.backbone(x)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet.py", line 277, in forward
    x = self.layer2(x)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet.py", line 69, in forward
    return self.relu(out + residual)
RuntimeError: CUDA out of memory. Tried to allocate 54.00 MiB (GPU 0; 31.75 GiB total capacity; 26.54 GiB already allocated; 39.94 MiB free; 26.62 GiB reserved in total by PyTorch)
2021-06-14 15:47:17,084 [ train_loader has [2045, 1631, 1882, 1832, 1839, 1654, 1931] samples ]
2021-06-14 15:47:17,478 Setting up Sem Seg model
2021-06-14 15:47:17,478 

Setting up GPS sensor
2021-06-14 15:47:17,479 

Setting up Compass sensor
2021-06-14 15:47:17,479 

Setting up Object Goal sensor
2021-06-14 15:47:17,697 Initializing task ObjectNav-v1
2021-06-14 15:47:17,920 [ train_loader has [2044, 1509, 1613, 2058, 2024, 1996, 1570] samples ]
2021-06-14 15:47:18,250 Setting up Sem Seg model
2021-06-14 15:47:18,251 

Setting up GPS sensor
2021-06-14 15:47:18,251 

Setting up Compass sensor
2021-06-14 15:47:18,251 

Setting up Object Goal sensor
2021-06-14 15:47:26,727 agent number of trainable parameters: 11051982
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/tensorflow-1.13.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 342, in train
    ) = self._update_agent(il_cfg, rollouts)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_trainer.py", line 267, in _update_agent
    total_loss, rnn_hidden_states = self.agent.update(rollouts)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/agent.py", line 75, in update
    masks_batch,
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 337, in forward
    observations, rnn_hidden_states, prev_actions, masks
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 275, in forward
    sem_seg_embedding = self.sem_seg_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rearrangement/models/encoders/resnet_encoders.py", line 395, in forward
    x = self.visual_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet_policy.py", line 218, in forward
    x = self.backbone(x)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet.py", line 276, in forward
    x = self.layer1(x)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet.py", line 64, in forward
    out = self.convs(x)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 423, in forward
    return self._conv_forward(input, self.weight)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 420, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 106.00 MiB (GPU 0; 31.75 GiB total capacity; 25.88 GiB already allocated; 15.25 MiB free; 25.94 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 342, in train
    ) = self._update_agent(il_cfg, rollouts)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_trainer.py", line 267, in _update_agent
    total_loss, rnn_hidden_states = self.agent.update(rollouts)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/agent.py", line 75, in update
    masks_batch,
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 337, in forward
    observations, rnn_hidden_states, prev_actions, masks
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 275, in forward
    sem_seg_embedding = self.sem_seg_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rearrangement/models/encoders/resnet_encoders.py", line 395, in forward
    x = self.visual_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet_policy.py", line 209, in forward
    x = torch.cat(cnn_input, dim=1)
RuntimeError: CUDA out of memory. Tried to allocate 4.10 GiB (GPU 0; 31.75 GiB total capacity; 19.82 GiB already allocated; 2.53 GiB free; 21.33 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 342, in train
    ) = self._update_agent(il_cfg, rollouts)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_trainer.py", line 267, in _update_agent
    total_loss, rnn_hidden_states = self.agent.update(rollouts)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/agent.py", line 75, in update
    masks_batch,
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 337, in forward
    observations, rnn_hidden_states, prev_actions, masks
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 275, in forward
    sem_seg_embedding = self.sem_seg_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rearrangement/models/encoders/resnet_encoders.py", line 395, in forward
    x = self.visual_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet_policy.py", line 209, in forward
    x = torch.cat(cnn_input, dim=1)
RuntimeError: CUDA out of memory. Tried to allocate 4.10 GiB (GPU 0; 31.75 GiB total capacity; 19.82 GiB already allocated; 2.46 GiB free; 21.33 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 342, in train
    ) = self._update_agent(il_cfg, rollouts)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_trainer.py", line 267, in _update_agent
    total_loss, rnn_hidden_states = self.agent.update(rollouts)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/agent.py", line 75, in update
    masks_batch,
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 337, in forward
    observations, rnn_hidden_states, prev_actions, masks
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 275, in forward
    sem_seg_embedding = self.sem_seg_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rearrangement/models/encoders/resnet_encoders.py", line 395, in forward
    x = self.visual_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet_policy.py", line 209, in forward
    x = torch.cat(cnn_input, dim=1)
RuntimeError: CUDA out of memory. Tried to allocate 3.65 GiB (GPU 0; 31.75 GiB total capacity; 18.27 GiB already allocated; 1.94 GiB free; 21.52 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 342, in train
    ) = self._update_agent(il_cfg, rollouts)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_trainer.py", line 267, in _update_agent
    total_loss, rnn_hidden_states = self.agent.update(rollouts)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/agent.py", line 75, in update
    masks_batch,
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 337, in forward
    observations, rnn_hidden_states, prev_actions, masks
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 275, in forward
    sem_seg_embedding = self.sem_seg_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rearrangement/models/encoders/resnet_encoders.py", line 395, in forward
    x = self.visual_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet_policy.py", line 209, in forward
    x = torch.cat(cnn_input, dim=1)
RuntimeError: CUDA out of memory. Tried to allocate 4.04 GiB (GPU 0; 31.75 GiB total capacity; 19.60 GiB already allocated; 1.69 GiB free; 23.19 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 342, in train
    ) = self._update_agent(il_cfg, rollouts)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_trainer.py", line 267, in _update_agent
    total_loss, rnn_hidden_states = self.agent.update(rollouts)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/agent.py", line 75, in update
    masks_batch,
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 337, in forward
    observations, rnn_hidden_states, prev_actions, masks
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/models/sem_seg_model.py", line 275, in forward
    sem_seg_embedding = self.sem_seg_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rearrangement/models/encoders/resnet_encoders.py", line 395, in forward
    x = self.visual_encoder(observations)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/rl/ddppo/policy/resnet_policy.py", line 209, in forward
    x = torch.cat(cnn_input, dim=1)
RuntimeError: CUDA out of memory. Tried to allocate 4.10 GiB (GPU 0; 31.75 GiB total capacity; 19.82 GiB already allocated; 3.61 GiB free; 21.33 GiB reserved in total by PyTorch)
slurmstepd: error: *** STEP 42540806.1 ON learnfair1625 CANCELLED AT 2021-06-14T15:58:00 ***
slurmstepd: error: *** JOB 42540806 ON learnfair1625 CANCELLED AT 2021-06-14T15:58:00 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
