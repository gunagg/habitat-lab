+ [[ env_sem == \e\n\v ]]
+ [[ env_sem == \e\n\v\_\s\e\m ]]
+ echo 'In ObjectNav Env DDP SemSeg'
+ srun /private/home/abhshkdz/.conda/envs/habitat-on-web/bin/python -u -m habitat_baselines.run --exp-config habitat_baselines/config/objectnav/il_ddp_env_objectnav_semseg.yaml --run-type train
2022-01-26 10:24:30,413 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,414 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    INSTRUCTION_SENSOR_UUID: instruction
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,414 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    use_normalized_advantage: True
    value_loss_coef: 0.5
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    use_normalized_advantage: True
    value_loss_coef: 0.5
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    INSTRUCTION_SENSOR_UUID: instruction
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
2022-01-26 10:24:30,414 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    INSTRUCTION_SENSOR_UUID: instruction
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,416 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,414 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
    use_normalized_advantage: True
    value_loss_coef: 0.5
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    use_normalized_advantage: True
    value_loss_coef: 0.5
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    use_normalized_advantage: True
    value_loss_coef: 0.5
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
2022-01-26 10:24:30,414 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
    INSTRUCTION_SENSOR_UUID: instruction
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,414 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:30,417 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,417 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:30,416 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:30,416 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    INSTRUCTION_SENSOR_UUID: instruction
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    INSTRUCTION_SENSOR_UUID: instruction
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,414 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
2022-01-26 10:24:30,417 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:30,416 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    use_normalized_advantage: True
    value_loss_coef: 0.5
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    use_normalized_advantage: True
    value_loss_coef: 0.5
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
2022-01-26 10:24:30,417 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:30,418 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    INSTRUCTION_SENSOR_UUID: instruction
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    use_normalized_advantage: True
    value_loss_coef: 0.5
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    INSTRUCTION_SENSOR_UUID: instruction
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
2022-01-26 10:24:30,417 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:30,416 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    use_normalized_advantage: True
    value_loss_coef: 0.5
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:30,418 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    INSTRUCTION_SENSOR_UUID: instruction
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    use_normalized_advantage: True
    value_loss_coef: 0.5
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,418 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    use_normalized_advantage: True
    value_loss_coef: 0.5
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:30,418 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    use_normalized_advantage: True
    value_loss_coef: 0.5
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
2022-01-26 10:24:30,417 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:30,416 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    use_normalized_advantage: True
    value_loss_coef: 0.5
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:30,418 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,414 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    INSTRUCTION_SENSOR_UUID: instruction
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    use_normalized_advantage: True
    value_loss_coef: 0.5
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    use_normalized_advantage: True
    value_loss_coef: 0.5
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
2022-01-26 10:24:30,418 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:30,416 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:30,418 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    INSTRUCTION_SENSOR_UUID: instruction
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    use_normalized_advantage: True
    value_loss_coef: 0.5
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,417 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:30,416 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    use_normalized_advantage: True
    value_loss_coef: 0.5
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
2022-01-26 10:24:30,415 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    use_normalized_advantage: True
    value_loss_coef: 0.5
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    INSTRUCTION_SENSOR_UUID: instruction
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    use_normalized_advantage: True
    value_loss_coef: 0.5
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    INSTRUCTION_SENSOR_UUID: instruction
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    INSTRUCTION_SENSOR_UUID: instruction
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    INSTRUCTION_SENSOR_UUID: instruction
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    INSTRUCTION_SENSOR_UUID: instruction
    INSTRUCTION_SENSOR_UUID: instruction
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    INSTRUCTION_SENSOR_UUID: instruction
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:30,418 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    use_normalized_advantage: True
    value_loss_coef: 0.5
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    INSTRUCTION_SENSOR_UUID: instruction
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    INSTRUCTION_SENSOR_UUID: instruction
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    INSTRUCTION_SENSOR_UUID: instruction
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    INSTRUCTION_SENSOR_UUID: instruction
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    INSTRUCTION_SENSOR_UUID: instruction
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    INSTRUCTION_SENSOR_UUID: instruction
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    INSTRUCTION_SENSOR_UUID: instruction
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
2022-01-26 10:24:30,418 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    use_normalized_advantage: True
    value_loss_coef: 0.5
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    INSTRUCTION_SENSOR_UUID: instruction
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    INSTRUCTION_SENSOR_UUID: instruction
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:24:31,025 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:24:31,025 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:31,025 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:31,025 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:31,025 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:31,025 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:31,025 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:31,025 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:24:42,477 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:42,478 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:42,478 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:42,478 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:42,478 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
2022-01-26 10:24:42,478 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:24:42,478 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
2022-01-26 10:24:42,478 config: BASE_TASK_CONFIG_PATH: configs/tasks/objectnav_mp3d_il.yaml
CHECKPOINT_FOLDER: results/checkpoints/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu
CHECKPOINT_INTERVAL: 500
CMD_TRAILING_OPTS: []
DATASET_PATH: data/datasets/objectnav_mp3d_v2/{split}/{scene_split}.db
ENV_NAME: NavRLEnv
EVAL:
  SPLIT: val
  USE_CKPT_CONFIG: True
  evaluation_meta_file: tb/objectnav/overfitting/rgbd/seed_1/val_10/evaluation_meta.json
  sample: False
  semantic_metrics: True
EVAL_CKPT_PATH_DIR: data/new_checkpoints/objectnav/objectnav_env/v4_rgbd/objectnav_mp3d_v2_rgbd_8node_17_seed1.ckpt
EVAL_RESUTLS_DIR: data/objectnav_mp3d_v2/seed_1/results/
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
FORCE_BLIND_POLICY: False
IL:
  BehaviorCloning:
    clip_param: 0.2
    eps: 1e-05
    lr: 0.001
    max_grad_norm: 0.2
    num_mini_batch: 2
    num_steps: 64
    reward_window_size: 50
    sync_frac: 0.6
    use_linear_clip_decay: False
    use_linear_lr_decay: True
  USE_IW: True
  distrib_backend: GLOO
LOG_FILE: train.log
LOG_INTERVAL: 10
LOG_METRICS: True
MODEL:
  DEPTH_ENCODER:
    backbone: resnet50
    cnn_type: VlnResnetDepthEncoder
    ddppo_checkpoint: data/ddppo-models/gibson-2plus-resnet50.pth
    output_size: 128
    trainable: False
  NO_VISION: False
  PROGRESS_MONITOR:
    use: False
  RGB_ENCODER:
    backbone: resnet18
    cnn_type: ResnetRGBEncoder
    output_size: 256
    train_encoder: True
  SEMANTIC_ENCODER:
    backbone: resnet18
    cnn_type: ResnetSemSegEncoder
    embedding_size: 4
    is_thda: True
    num_classes: 29
    output_size: 256
    rednet_ckpt: data/rednet-models/rednet_semmap_mp3d_40_v2_vince.pth
    train_encoder: True
  SEQ2SEQ:
    use_prev_action: True
  STATE_ENCODER:
    hidden_size: 2048
    num_recurrent_layers: 2
    rnn_type: GRU
  SWITCH_TO_PRED_SEMANTICS_UPDATE: 0
  USE_PRED_SEMANTICS: True
  USE_SEMANTICS: True
  ablate_depth: False
  ablate_rgb: False
  backbone: resnet18
  embed_goal_seg: False
  embed_sge: True
  force_blind_policy: False
  inflection_weight_coef: 3.526493623206225
  normalize_visual_inputs: False
  num_recurrent_layers: 2
  resnet_baseplanes: 32
  rnn_type: GRU
NUM_PROCESSES: 8
NUM_UPDATES: 16000
ORBSLAM2:
  ANGLE_TH: 0.2617993877991494
  BETA: 100
  CAMERA_HEIGHT: 1.25
  DEPTH_DENORM: 10.0
  DIST_REACHED_TH: 0.15
  DIST_TO_STOP: 0.05
  D_OBSTACLE_MAX: 4.0
  D_OBSTACLE_MIN: 0.1
  H_OBSTACLE_MAX: 1.25
  H_OBSTACLE_MIN: 0.375
  MAP_CELL_SIZE: 0.1
  MAP_SIZE: 40
  MIN_PTS_IN_OBSTACLE: 320.0
  NEXT_WAYPOINT_TH: 0.5
  NUM_ACTIONS: 3
  PLANNER_MAX_STEPS: 500
  PREPROCESS_MAP: True
  SLAM_SETTINGS_PATH: habitat_baselines/slambased/data/mp3d3_small1k.yaml
  SLAM_VOCAB_PATH: habitat_baselines/slambased/data/ORBvoc.txt
OUTPUT_LOG_DIR: results/logs/objectnav_mp3d_v2/seed_1
PROFILING:
  CAPTURE_START_STEP: -1
  NUM_STEPS_TO_CAPTURE: -1
RESULTS_DIR: results/objectnav_mp3d_v2/seed_1/results/{split}/{type}
RL:
  DDPPO:
    backbone: resnet50
    distrib_backend: GLOO
    num_recurrent_layers: 2
    pretrained: False
    pretrained_encoder: False
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    reset_critic: True
    rnn_type: LSTM
    sync_frac: 0.6
    train_encoder: True
  POLICY:
    OBS_TRANSFORMS:
      CENTER_CROPPER:
        HEIGHT: 256
        WIDTH: 256
      CUBE2EQ:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 512
      CUBE2FISH:
        FOV: 180
        HEIGHT: 256
        PARAMS: (0.2, 0.2, 0.2)
        SENSOR_UUIDS: []
        WIDTH: 256
      ENABLED_TRANSFORMS: ()
      EQ2CUBE:
        HEIGHT: 256
        SENSOR_UUIDS: []
        WIDTH: 256
      RESIZE_SHORTEST_EDGE:
        SIZE: 256
    name: PointNavBaselinePolicy
  PPO:
    clip_param: 0.2
    entropy_coef: 0.01
    eps: 1e-05
    gamma: 0.99
    hidden_size: 512
    lr: 0.0007
    max_grad_norm: 0.5
    num_mini_batch: 16
    num_steps: 5
    ppo_epoch: 4
    reward_window_size: 50
    tau: 0.95
    use_gae: True
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    use_normalized_advantage: True
    value_loss_coef: 0.5
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
  REWARD_MEASURE: distance_to_goal
  SLACK_REWARD: -0.001
  SUCCESS_MEASURE: spl
  SUCCESS_REWARD: 2.5
SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'SEMANTIC_SENSOR']
SHOW_TOP_DOWN_MAP: False
SIMULATOR_GPU_ID: 0
TASK_CONFIG:
  DATASET:
    CONTENT_SCENES: ['*']
    DATA_PATH: data/datasets/objectnav_mp3d_thda_45k/{split}/{split}.json.gz
    SCENES_DIR: data/scene_datasets/
    SPLIT: train
    TYPE: ObjectNav-v2
  ENVIRONMENT:
    ITERATOR_OPTIONS:
      CYCLE: True
      GROUP_BY_SCENE: True
      MAX_SCENE_REPEAT_EPISODES: -1
      MAX_SCENE_REPEAT_STEPS: 10000
      NUM_EPISODE_SAMPLE: -1
      SHUFFLE: True
      STEP_REPETITION_RANGE: 0.2
    MAX_EPISODE_SECONDS: 10000000
    MAX_EPISODE_STEPS: 5000
  PYROBOT:
    BASE_CONTROLLER: proportional
    BASE_PLANNER: none
    BUMP_SENSOR:
      TYPE: PyRobotBumpSensor
    DEPTH_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.0
      NORMALIZE_DEPTH: True
      TYPE: PyRobotDepthSensor
      WIDTH: 640
    LOCOBOT:
      ACTIONS: ['BASE_ACTIONS', 'CAMERA_ACTIONS']
      BASE_ACTIONS: ['go_to_relative', 'go_to_absolute']
      CAMERA_ACTIONS: ['set_pan', 'set_tilt', 'set_pan_tilt']
    RGB_SENSOR:
      CENTER_CROP: False
      HEIGHT: 480
      TYPE: PyRobotRGBSensor
      WIDTH: 640
    ROBOT: locobot
    ROBOTS: ['locobot']
    SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR', 'BUMP_SENSOR']
  SEED: 105
  SIMULATOR:
    ACTION_SPACE_CONFIG: v1
    AGENTS: ['AGENT_0']
    AGENT_0:
      ANGULAR_ACCELERATION: 12.56
      ANGULAR_FRICTION: 1.0
      COEFFICIENT_OF_RESTITUTION: 0.0
      HEIGHT: 0.88
      IS_SET_START_STATE: False
      LINEAR_ACCELERATION: 20.0
      LINEAR_FRICTION: 0.5
      MASS: 32.0
      RADIUS: 0.18
      SENSORS: ['RGB_SENSOR', 'DEPTH_SENSOR']
      START_POSITION: [0, 0, 0]
      START_ROTATION: [0, 0, 0, 1]
    DEFAULT_AGENT_ID: 0
    DEPTH_SENSOR:
      HEIGHT: 480
      HFOV: 79
      MAX_DEPTH: 5.0
      MIN_DEPTH: 0.5
      NORMALIZE_DEPTH: True
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimDepthSensor
      WIDTH: 640
    FORWARD_STEP_SIZE: 0.25
    HABITAT_SIM_V0:
      ALLOW_SLIDING: False
      ENABLE_PHYSICS: False
      GPU_DEVICE_ID: 0
      GPU_GPU: False
      PHYSICS_CONFIG_FILE: ./data/default.physics_config.json
    RGB_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimRGBSensor
      WIDTH: 640
    SCENE: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    SEED: 100
    SEMANTIC_SENSOR:
      HEIGHT: 480
      HFOV: 79
      ORIENTATION: [0.0, 0.0, 0.0]
      POSITION: [0, 0.88, 0]
      TYPE: HabitatSimSemanticSensor
      WIDTH: 640
    TILT_ANGLE: 30
    TURN_ANGLE: 30
    TYPE: Sim-v0
  TASK:
    ACTIONS:
      ANSWER:
        TYPE: AnswerAction
      LOOK_DOWN:
        TYPE: LookDownAction
      LOOK_UP:
        TYPE: LookUpAction
      MOVE_FORWARD:
        TYPE: MoveForwardAction
      STOP:
        TYPE: StopAction
      TELEPORT:
        TYPE: TeleportAction
      TURN_LEFT:
        TYPE: TurnLeftAction
      TURN_RIGHT:
        TYPE: TurnRightAction
    ALL_OBJECT_POSITIONS:
      TYPE: AllObjectPositions
    ANSWER_ACCURACY:
      TYPE: AnswerAccuracy
    COLLISIONS:
      TYPE: Collisions
    COMPASS_SENSOR:
      TYPE: CompassSensor
    CORRECT_ANSWER:
      TYPE: CorrectAnswer
    DEMONSTRATION_SENSOR:
      TYPE: DemonstrationSensor
    DEMONSTRATION_SENSOR_UUID: demonstration
    DISTANCE_TO_GOAL:
      DISTANCE_TO: VIEW_POINTS
      TYPE: DistanceToGoal
    EPISODE_INFO:
      TYPE: EpisodeInfo
    GOAL_SENSOR_UUID: objectgoal
    GPS_SENSOR:
      DIMENSIONALITY: 2
      TYPE: GPSSensor
    HEADING_SENSOR:
      TYPE: HeadingSensor
    IMAGEGOAL_SENSOR:
      TYPE: ImageGoalSensor
    INCREASE_DIST: False
    INFLECTION_WEIGHT_SENSOR:
      INFLECTION_COEF: 3.526493623206225
      TYPE: InflectionWeightSensor
    INFLECTION_WEIGHT_SENSOR_UUID: inflection_weight
    INSTRUCTION_SENSOR:
      TYPE: InstructionSensor
    INSTRUCTION_SENSOR_UUID: instruction
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
    MEASUREMENTS: ['DISTANCE_TO_GOAL', 'SUCCESS', 'SPL', 'SOFT_SPL']
    NUM_OBJECT_COPIES: 3
    NUM_UNIQ_SELECTED_OBJECTS: 5
    OBJECTGOAL_SENSOR:
      GOAL_SPEC: TASK_CATEGORY_ID
      GOAL_SPEC_MAX_VAL: 50
      TYPE: ObjectGoalSensor
    OBJ_GEN_FAR_DIST: 5.0
    OBJ_GEN_NEAR_DIST: 1.0
    POINTGOAL_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalSensor
    POINTGOAL_WITH_GPS_COMPASS_SENSOR:
      DIMENSIONALITY: 2
      GOAL_FORMAT: POLAR
      TYPE: PointGoalWithGPSCompassSensor
    POSSIBLE_ACTIONS: ['STOP', 'MOVE_FORWARD', 'TURN_LEFT', 'TURN_RIGHT', 'LOOK_UP', 'LOOK_DOWN']
    PROXIMITY_SENSOR:
      MAX_DETECTION_RADIUS: 2.0
      TYPE: ProximitySensor
    QUESTION_SENSOR:
      TYPE: QuestionSensor
    ROOM_REVISITATION_MAP:
      TYPE: RoomRevisitationMap
    ROOM_VISITATION_MAP:
      TYPE: RoomVisitationMap
    SENSORS: ['OBJECTGOAL_SENSOR', 'COMPASS_SENSOR', 'GPS_SENSOR', 'DEMONSTRATION_SENSOR', 'INFLECTION_WEIGHT_SENSOR']
    SOFT_SPL:
      TYPE: SoftSPL
    SPL:
      TYPE: SPL
    SUCCESS:
      SUCCESS_DISTANCE: 0.1
      THDA_SUCCESS_DISTANCE: 1.0
      TYPE: Success
    SUCCESS_DISTANCE: 0.1
    TOP_DOWN_MAP:
      DRAW_BORDER: True
      DRAW_GOAL_AABBS: False
      DRAW_GOAL_POSITIONS: True
      DRAW_SHORTEST_PATH: False
      DRAW_SOURCE: True
      DRAW_VIEW_POINTS: True
      FOG_OF_WAR:
        DRAW: True
        FOV: 90
        VISIBILITY_DIST: 5.0
      MAP_PADDING: 3
      MAP_RESOLUTION: 256
      MAX_EPISODE_STEPS: 1000
      TYPE: TopDownMap
    TYPE: ObjectNav-v1
TENSORBOARD_DIR: results/tb/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
TEST_EPISODE_COUNT: -1
TORCH_GPU_ID: 0
TRAINER_NAME: ddp-objectnav-bc-env
VIDEO_DIR: results/videos/objectnav_mp3d_thda_45k/seed_1/2022_01_26_semseg_64gpu/
VIDEO_OPTION: ['disk']
2022-01-26 10:24:44,930 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
2022-01-26 10:24:44,949 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
2022-01-26 10:24:44,984 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
2022-01-26 10:24:45,003 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
2022-01-26 10:24:45,010 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
2022-01-26 10:24:45,011 Initializing dataset ObjectNav-v2
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    assert cls.check_config_paths_exist(config)
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
AssertionError
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
2022-01-26 10:24:45,014 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
2022-01-26 10:24:45,017 Initializing dataset ObjectNav-v2
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
2022-01-26 10:24:45,018 Initializing dataset ObjectNav-v2
2022-01-26 10:24:45,019 Initializing dataset ObjectNav-v2
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    assert cls.check_config_paths_exist(config)
AssertionError
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
2022-01-26 10:24:45,021 Initializing dataset ObjectNav-v2
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    assert cls.check_config_paths_exist(config)
AssertionError
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
2022-01-26 10:24:45,026 Initializing dataset ObjectNav-v2
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    assert cls.check_config_paths_exist(config)
AssertionError
AssertionError
    assert cls.check_config_paths_exist(config)
AssertionError
2022-01-26 10:24:45,029 Initializing dataset ObjectNav-v2
2022-01-26 10:24:45,029 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
2022-01-26 10:24:45,030 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
2022-01-26 10:24:45,031 Initializing dataset ObjectNav-v2
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
Traceback (most recent call last):
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
2022-01-26 10:24:45,032 Initializing dataset ObjectNav-v2
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    execute_exp(config, run_type)
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    assert cls.check_config_paths_exist(config)
    assert cls.check_config_paths_exist(config)
AssertionError
AssertionError
    assert cls.check_config_paths_exist(config)
AssertionError
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
2022-01-26 10:24:45,034 Initializing dataset ObjectNav-v2
    assert cls.check_config_paths_exist(config)
AssertionError
2022-01-26 10:24:45,035 Initializing dataset ObjectNav-v2
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    assert cls.check_config_paths_exist(config)
AssertionError
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
2022-01-26 10:24:45,038 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    assert cls.check_config_paths_exist(config)
AssertionError
2022-01-26 10:24:45,038 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
2022-01-26 10:24:45,039 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
2022-01-26 10:24:45,041 Initializing dataset ObjectNav-v2
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    assert cls.check_config_paths_exist(config)
AssertionError
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
2022-01-26 10:24:45,043 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    assert cls.check_config_paths_exist(config)
AssertionError
    assert cls.check_config_paths_exist(config)
AssertionError
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    assert cls.check_config_paths_exist(config)
AssertionError
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    assert cls.check_config_paths_exist(config)
AssertionError
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
2022-01-26 10:24:45,045 Initializing dataset ObjectNav-v2
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    assert cls.check_config_paths_exist(config)
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
AssertionError
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
2022-01-26 10:24:45,046 Initializing dataset ObjectNav-v2
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    assert cls.check_config_paths_exist(config)
AssertionError
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
2022-01-26 10:24:45,048 Initializing dataset ObjectNav-v2
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
2022-01-26 10:24:45,048 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    trainer.train()
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    assert cls.check_config_paths_exist(config)
AssertionError
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
2022-01-26 10:24:45,050 Initializing dataset ObjectNav-v2
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    assert cls.check_config_paths_exist(config)
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
AssertionError
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    assert cls.check_config_paths_exist(config)
AssertionError
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    assert cls.check_config_paths_exist(config)
AssertionError
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
2022-01-26 10:24:45,053 Initializing dataset ObjectNav-v2
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
2022-01-26 10:24:45,054 Initializing dataset ObjectNav-v2
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
Traceback (most recent call last):
2022-01-26 10:24:45,054 Initializing dataset ObjectNav-v2
2022-01-26 10:24:45,054 Initializing dataset ObjectNav-v2
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
Traceback (most recent call last):
    assert cls.check_config_paths_exist(config)
AssertionError
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
2022-01-26 10:24:45,054 Initializing dataset ObjectNav-v2
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
Traceback (most recent call last):
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
2022-01-26 10:24:45,057 Initializing dataset ObjectNav-v2
2022-01-26 10:24:45,057 Initializing dataset ObjectNav-v2
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    assert cls.check_config_paths_exist(config)
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
AssertionError
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    assert cls.check_config_paths_exist(config)
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
AssertionError
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    exec(code, run_globals)
    assert cls.check_config_paths_exist(config)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
AssertionError
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
2022-01-26 10:24:45,058 Initializing dataset ObjectNav-v2
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
Traceback (most recent call last):
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
2022-01-26 10:24:45,059 Initializing dataset ObjectNav-v2
2022-01-26 10:24:45,059 Initializing dataset ObjectNav-v2
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
2022-01-26 10:24:45,060 Initializing dataset ObjectNav-v2
    assert cls.check_config_paths_exist(config)
AssertionError
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    main()
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
2022-01-26 10:24:45,061 Initializing dataset ObjectNav-v2
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    run_exp(**vars(args))
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
2022-01-26 10:24:45,061 Initializing dataset ObjectNav-v2
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    assert cls.check_config_paths_exist(config)
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
AssertionError
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    assert cls.check_config_paths_exist(config)
AssertionError
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
2022-01-26 10:24:45,063 Initializing dataset ObjectNav-v2
    assert cls.check_config_paths_exist(config)
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
AssertionError
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    assert cls.check_config_paths_exist(config)
AssertionError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
2022-01-26 10:24:45,064 Initializing dataset ObjectNav-v2
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    assert cls.check_config_paths_exist(config)
AssertionError
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
2022-01-26 10:24:45,065 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    execute_exp(config, run_type)
2022-01-26 10:24:45,066 Initializing dataset ObjectNav-v2
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
2022-01-26 10:24:45,066 Initializing dataset ObjectNav-v2
2022-01-26 10:24:45,066 Initializing dataset ObjectNav-v2
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    assert cls.check_config_paths_exist(config)
AssertionError
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    assert cls.check_config_paths_exist(config)
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
AssertionError
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    assert cls.check_config_paths_exist(config)
AssertionError
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
2022-01-26 10:24:45,070 Initializing dataset ObjectNav-v2
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    assert cls.check_config_paths_exist(config)
AssertionError
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
2022-01-26 10:24:45,072 Initializing dataset ObjectNav-v2
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
2022-01-26 10:24:45,073 Initializing dataset ObjectNav-v2
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
2022-01-26 10:24:45,073 Initializing dataset ObjectNav-v2
    assert cls.check_config_paths_exist(config)
AssertionError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
Traceback (most recent call last):
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
2022-01-26 10:24:45,073 Initializing dataset ObjectNav-v2
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
2022-01-26 10:24:45,074 Initializing dataset ObjectNav-v2
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
Traceback (most recent call last):
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    assert cls.check_config_paths_exist(config)
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
AssertionError
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
2022-01-26 10:24:45,076 Initializing dataset ObjectNav-v2
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
2022-01-26 10:24:45,076 Initializing dataset ObjectNav-v2
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    assert cls.check_config_paths_exist(config)
AssertionError
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    assert cls.check_config_paths_exist(config)
2022-01-26 10:24:45,076 Initializing dataset ObjectNav-v2
AssertionError
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    assert cls.check_config_paths_exist(config)
2022-01-26 10:24:45,077 Initializing dataset ObjectNav-v2
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
AssertionError
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    assert cls.check_config_paths_exist(config)
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
2022-01-26 10:24:45,078 Initializing dataset ObjectNav-v2
AssertionError
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    assert cls.check_config_paths_exist(config)
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
AssertionError
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
2022-01-26 10:24:45,078 Initializing dataset ObjectNav-v2
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    assert cls.check_config_paths_exist(config)
AssertionError
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
Traceback (most recent call last):
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    assert cls.check_config_paths_exist(config)
AssertionError
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
2022-01-26 10:24:45,080 Initializing dataset ObjectNav-v2
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    assert cls.check_config_paths_exist(config)
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
AssertionError
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    assert cls.check_config_paths_exist(config)
2022-01-26 10:24:45,080 Initializing dataset ObjectNav-v2
AssertionError
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    "__main__", mod_spec)
    exec(code, run_globals)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    assert cls.check_config_paths_exist(config)
AssertionError
    run_exp(**vars(args))
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
2022-01-26 10:24:45,083 Initializing dataset ObjectNav-v2
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    assert cls.check_config_paths_exist(config)
AssertionError
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
2022-01-26 10:24:45,085 Initializing dataset ObjectNav-v2
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
Traceback (most recent call last):
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    assert cls.check_config_paths_exist(config)
AssertionError
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    "__main__", mod_spec)
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/runpy.py", line 85, in _run_code
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    exec(code, run_globals)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 79, in <module>
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    main()
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 40, in main
    assert cls.check_config_paths_exist(config)
AssertionError
    run_exp(**vars(args))
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 75, in run_exp
    assert cls.check_config_paths_exist(config)
AssertionError
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    execute_exp(config, run_type)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/run.py", line 58, in execute_exp
    trainer.train()
  File "/private/home/abhshkdz/.conda/envs/habitat-on-web/lib/python3.6/contextlib.py", line 52, in inner
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    return func(*args, **kwds)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/objectnav/il/behavior_cloning_env_ddp_trainer.py", line 175, in train
    workers_ignore_signals=True,
  File "/private/home/abhshkdz/projects/habitat-lab/habitat_baselines/utils/env_utils.py", line 59, in construct_envs
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    scenes = dataset.get_scenes_to_load(config.TASK_CONFIG.DATASET)
  File "/private/home/abhshkdz/projects/habitat-lab/habitat/datasets/pointnav/pointnav_dataset.py", line 44, in get_scenes_to_load
    assert cls.check_config_paths_exist(config)
AssertionError
    assert cls.check_config_paths_exist(config)
AssertionError
srun: error: learnfair1636: tasks 8-14: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=52464949.1
srun: error: learnfair1634: tasks 1-7: Exited with exit code 1
srun: error: learnfair1642: tasks 24-26,28-31: Exited with exit code 1
srun: error: learnfair1769: tasks 32-34,36-39: Exited with exit code 1
srun: error: learnfair1772: tasks 48-50,52-55: Exited with exit code 1
srun: error: learnfair1771: tasks 40-41,43-47: Exited with exit code 1
srun: error: learnfair1957: tasks 56-58,60-63: Exited with exit code 1
srun: error: learnfair1640: tasks 16-22: Exited with exit code 1
srun: error: learnfair1640: task 23: Exited with exit code 1
srun: error: learnfair1769: task 35: Exited with exit code 1
srun: error: learnfair1771: task 42: Exited with exit code 1
srun: error: learnfair1634: task 0: Exited with exit code 1
srun: error: learnfair1772: task 51: Exited with exit code 1
srun: error: learnfair1636: task 15: Exited with exit code 1
srun: error: learnfair1957: task 59: Exited with exit code 1
srun: error: learnfair1642: task 27: Exited with exit code 1
