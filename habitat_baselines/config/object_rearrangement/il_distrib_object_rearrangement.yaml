# Note:  This is an example config, see habitat_baselines/config/pointnav/ppo_pointnav.yaml
# for better hyperparameters for actual training

BASE_TASK_CONFIG_PATH: "configs/tasks/object_rearrangement.yaml"
TRAINER_NAME: "rearrangement-behavior-cloning-distrib"
ENV_NAME: RearrangementRLEnv
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
VIDEO_OPTION: ["disk"]
TENSORBOARD_DIR: "tb/pick_and_place/unseen_scenes_v2/seed_2/test_unseen_ins/ckpt_20/"
VIDEO_DIR: "video_dir/pick_and_place/unseen_scenes_v2/seed_2/test_unseen_ins/ckpt_20/"
# To evaluate on all episodes, set this to -1d
TEST_EPISODE_COUNT: -1
EVAL_CKPT_PATH_DIR: "data/new_checkpoints/unseen_scenes_v2/seed_2/model_20.ckpt"
SHOW_TOP_DOWN_MAP: False
NUM_PROCESSES: 2
CHECKPOINT_FOLDER: "data/new_checkpoints/unseen_scenes_v2/seed_2/"
OUTPUT_LOG_DIR: data/object_rearrangement/logs
LOG_INTERVAL: 10
LOG_METRICS: True
CHECKPOINT_INTERVAL: 1
DATASET_PATH: "/srv/flash1/rramrakhya6/habitat-lab/data/datasets/object_rearrangement/unseen_scenes_v3/{split}/{scene_split}.db"
RESULTS_DIR: "data/object_rearrangement/results/{split}/{type}"
EVAL_RESUTLS_DIR: "data/object_rearrangement/results/"
EVAL_SAVE_RESULTS: True
EVAL_SAVE_RESULTS_INTERVAL: 50
EVAL:
  SPLIT: "test_unseen_ins"
  sample: False
  semantic_metrics: False
  evaluation_meta_file: "tb/pick_and_place/unseen_scenes_v2/seed_1/evaluation_meta_full_unseen_scenes_v2.json"

IL:
  USE_IW: True
  distrib_backend: GLOO
  BehaviorCloning:
    lr: 0.001
    max_epochs: 20
    batch_size: 8
    timestep_batch_size: 256
    freeze_encoder: False

RL:
  REWARD_MEASURE: "rearrangement_reward"
  REWARD_MEASURE_2: "agent_object_distance"
  SUCCESS_MEASURE: "success"
  SLACK_REWARD: -0.01
  SUCCESS_REWARD: 2.5
  GRAB_SUCCESS_REWARD: 1.5

MODEL:
  inflection_weight_coef: 6.975176928855059
  ablate_depth: False
  ablate_rgb: False
  ablate_instruction: False
  INSTRUCTION_ENCODER:
    vocab_size: 128
    embedding_size: 64
    hidden_size: 128
    use_pretrained_embeddings: False
    rnn_type: "LSTM"
    final_state_only: True
    bidirectional: False
  RGB_ENCODER:
    cnn_type: "ResnetRGBEncoder"
    output_size: 256
    backbone: "resnet18"
    train_encoder: True
  DEPTH_ENCODER:
    cnn_type: "VlnResnetDepthEncoder"
    output_size: 128
    backbone: "resnet50"
    trainable: False
    ddppo_checkpoint: "data/ddppo-models/gibson-2plus-resnet50.pth"
  STATE_ENCODER:
    hidden_size: 512
    rnn_type: "GRU"
    num_recurrent_layers: 2
  SEQ2SEQ:
    use_prev_action: True
  PROGRESS_MONITOR:
    use: False